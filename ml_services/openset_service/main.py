"""
Open Set Recognition í…ŒìŠ¤íŠ¸ ë° ë””ë²„ê¹…
ResNet50 ë²„ì „ - ì´ë¯¸ì§€ í’ˆì§ˆ ê²€ì‚¬ + TTA í†µí•©
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from torchvision import models, transforms
import cv2
import os
import logging
from PIL import Image
from sklearn.covariance import EmpiricalCovariance

# ========================
# ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ - ResNet50 ë²„ì „
# ========================

class CalibratedOpenSetModel(nn.Module):
    """ResNet50 ë°±ë³¸ì„ ì‚¬ìš©í•˜ëŠ” Open Set ëª¨ë¸"""
    def __init__(self, num_classes=4, feature_dim=512, initial_temperature=1.5):
        super().__init__()
        
        # ResNet50 ë°±ë³¸ (ResNet101ì—ì„œ ë³€ê²½)
        resnet = models.resnet50(weights=None)
        self.features = nn.Sequential(*list(resnet.children())[:-1])
        
        # ResNet50ì˜ ì¶œë ¥ ì°¨ì›ì€ 2048 (ResNet101ê³¼ ë™ì¼)
        self.encoder = nn.Sequential(
            nn.Linear(2048, 1024),
            nn.BatchNorm1d(1024),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(1024, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, feature_dim)
        )
        
        self.main_classifier = nn.Linear(feature_dim, num_classes)
        self.auxiliary_classifier = nn.Linear(feature_dim, num_classes)
        
        self.decoder = nn.Sequential(
            nn.Linear(feature_dim, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Linear(512, 1024),
            nn.BatchNorm1d(1024),
            nn.ReLU(),
            nn.Linear(1024, 2048)
        )
        
        self.prototype_layer = nn.Linear(feature_dim, num_classes, bias=False)
        self.temperature = nn.Parameter(torch.ones(1) * initial_temperature)
    
    def forward(self, x, return_all=False, apply_temperature=True):
        cnn_features = self.features(x)
        cnn_features = cnn_features.view(cnn_features.size(0), -1)
        
        features = self.encoder(cnn_features)
        logits = self.main_classifier(features)
        aux_logits = self.auxiliary_classifier(features)
        
        # Temperature scaling
        if apply_temperature:
            temperature = torch.clamp(self.temperature, min=0.5, max=3.0)
            logits = logits / temperature
            aux_logits = aux_logits / temperature
        
        prototypes = F.normalize(self.prototype_layer.weight, dim=1)
        normalized_features = F.normalize(features, dim=1)
        distances = torch.cdist(normalized_features.unsqueeze(1),
                               prototypes.unsqueeze(0), p=2).squeeze(1)
        
        if return_all:
            reconstructed = self.decoder(features)
            reconstruction_error = F.mse_loss(reconstructed, cnn_features, reduction='none')
            reconstruction_error = reconstruction_error.mean(dim=1)
            
            return {
                'logits': logits,
                'aux_logits': aux_logits,
                'features': features,
                'reconstruction_error': reconstruction_error,
                'distances': distances,
                'cnn_features': cnn_features,
                'temperature': self.temperature.item()
            }
        
        return logits, features

# ========================
# ê°œì„ ëœ ì¸ì‹ê¸°
# ========================

class ImprovedOpenSetRecognizer:
    def __init__(self, model_path='improved_model_resnet50.pth', device='cpu'):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        self.logger = logging.getLogger(__name__)
        
        self.known_insects = {
            0: "ê½ƒë…¸ë‘ì´ì±„ë²Œë ˆ",
            1: "ë‹´ë°°ê°€ë£¨ì´",
            2: "ë³µìˆ­ì•„í˜¹ì§„ë”§ë¬¼",
            3: "ì©ë©ë‚˜ë¬´ë…¸ë¦°ì¬"
        }
        
        self._load_model(model_path)
        
        self.transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        self.logger.info(f"âœ… ResNet50 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
        self.logger.info(f"ğŸ“Š Device: {self.device}")
    
    def _load_model(self, model_path):
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        
        checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
        
        # ëª¨ë¸ ì´ˆê¸°í™” (temperature í¬í•¨)
        config = checkpoint.get('config', {})
        
        # ë°±ë³¸ ì •ë³´ í™•ì¸
        backbone = config.get('backbone', 'resnet50')
        self.logger.info(f"ğŸ“¦ ë°±ë³¸: {backbone}")
        
        self.model = CalibratedOpenSetModel(
            num_classes=config.get('num_classes', 4),
            feature_dim=config.get('feature_dim', 512),
            initial_temperature=config.get('temperature', 1.5)
        )
        
        # state_dict ë¡œë“œ (strict=Falseë¡œ í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°)
        state_dict = checkpoint['model_state']
        
        # í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°: strict=False ì‚¬ìš©
        incompatible_keys = self.model.load_state_dict(state_dict, strict=False)
        
        if incompatible_keys.missing_keys:
            self.logger.warning(f"âš ï¸ Missing keys: {incompatible_keys.missing_keys}")
        if incompatible_keys.unexpected_keys:
            self.logger.warning(f"âš ï¸ Unexpected keys: {incompatible_keys.unexpected_keys}")
        self.model.to(self.device)
        self.model.eval()
        
        # ì„ê³„ê°’ ë° í†µê³„ ë¡œë“œ
        if 'thresholds' in checkpoint:
            self.original_thresholds = checkpoint['thresholds'].copy()
            self.thresholds = checkpoint['thresholds']
            self.logger.info("âœ… ì €ì¥ëœ ì„ê³„ê°’ ë¡œë“œ")
        else:
            # ResNet50ì— ë§ì¶˜ ê¸°ë³¸ ì„ê³„ê°’
            self.logger.warning("âš ï¸ ì €ì¥ëœ ì„ê³„ê°’ ì—†ìŒ - ResNet50 ê¸°ë³¸ê°’ ì‚¬ìš©")
            self.original_thresholds = {
                'max_prob': 0.6,
                'entropy': 0.3,
                'min_distance': 1.5,
                'mahal_distance': 60.0,
                'recon_error': 0.08,
                'known_acc': 0.75,
                'unknown_reject': 0.65
            }
            self.thresholds = self.original_thresholds.copy()
        
        if 'class_statistics' in checkpoint:
            self.class_statistics = checkpoint['class_statistics']
            self.logger.info("âœ… í´ë˜ìŠ¤ í†µê³„ ë¡œë“œ")
        else:
            self.logger.warning("âš ï¸ í´ë˜ìŠ¤ í†µê³„ ì—†ìŒ")
            self.class_statistics = {}
        
        # ì„ê³„ê°’ ì¡°ì •
        self._adjust_thresholds()
    
    def _adjust_thresholds(self):
        """ê°œì„ ëœ ì„ê³„ê°’ ì¡°ì • - v2 ëª¨ë¸ì— ë§ì¶¤"""
        
        self.logger.info("ğŸ” ì›ë³¸ ì„ê³„ê°’:")
        for key, value in self.original_thresholds.items():
            if isinstance(value, float):
                self.logger.info(f"   - {key}: {value:.3f}")
        
        # ì €ì¥ëœ ì„ê³„ê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì´ë¯¸ ìµœì í™”ë¨)
        # ë‹¨, ì¼ë¶€ ë¯¸ì„¸ ì¡°ì •ë§Œ ìˆ˜í–‰
        
        # max_probëŠ” ì €ì¥ëœ ê°’ ì‚¬ìš© (ë³´í†µ 0.5 ì •ë„)
        if 'max_prob' in self.original_thresholds:
            self.thresholds['max_prob'] = self.original_thresholds['max_prob']
        else:
            self.thresholds['max_prob'] = 0.5
        
        # entropyëŠ” ì €ì¥ëœ ê°’ + ì•½ê°„ì˜ ì—¬ìœ 
        if 'entropy' in self.original_thresholds:
            self.thresholds['entropy'] = self.original_thresholds['entropy'] * 1.1  # 10% ê´€ëŒ€í•˜ê²Œ
        else:
            self.thresholds['entropy'] = 1.0
        
        # min_distanceëŠ” ì €ì¥ëœ ê°’ + ì—¬ìœ 
        if 'min_distance' in self.original_thresholds:
            self.thresholds['min_distance'] = self.original_thresholds['min_distance'] * 1.2  # 20% ê´€ëŒ€í•˜ê²Œ
        else:
            self.thresholds['min_distance'] = 2.0
        
        # recon_errorëŠ” ì €ì¥ëœ ê°’ + ì—¬ìœ 
        if 'recon_error' in self.original_thresholds:
            self.thresholds['recon_error'] = self.original_thresholds['recon_error'] * 1.2  # 20% ê´€ëŒ€í•˜ê²Œ
        else:
            self.thresholds['recon_error'] = 0.15
        
        # mahal_distanceëŠ” ê³ ì •ê°’ ì‚¬ìš©
        self.thresholds['mahal_distance'] = 20.0
        
        self.logger.info("ğŸ“ˆ v2 ëª¨ë¸ìš© ì¡°ì •ëœ ì„ê³„ê°’:")
        for key, value in self.thresholds.items():
            if key in ['max_prob', 'entropy', 'min_distance', 'recon_error', 'mahal_distance']:
                original = self.original_thresholds.get(key, 'N/A')
                if isinstance(original, float) and isinstance(value, float):
                    self.logger.info(f"   - {key}: {original:.3f} -> {value:.3f}")
                else:
                    self.logger.info(f"   - {key}: {original} -> {value}")
    
    def calculate_mahalanobis_distance(self, features):
        """ê°œì„ ëœ ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ ê³„ì‚°"""
        min_mahal = float('inf')
        best_class = -1
        
        # íŠ¹ì§• ì •ê·œí™” 
        features_norm = features / (np.linalg.norm(features) + 1e-8)
        
        for class_id, stats in self.class_statistics.items():
            if stats is not None:
                # ì •ê·œí™”ëœ í‰ê·  ì‚¬ìš©
                if 'mean_normalized' in stats:
                    mean_norm = stats['mean_normalized']
                else:
                    mean_norm = stats['mean'] / (np.linalg.norm(stats['mean']) + 1e-8)
                
                diff = features_norm - mean_norm
                
                if 'precision' in stats and stats['precision'] is not None:
                    try:
                        precision = stats['precision']
                        
                        # precision matrix ìŠ¤ì¼€ì¼ í™•ì¸
                        precision_scale = np.max(np.abs(precision))
                        if precision_scale > 100:
                            precision = precision / precision_scale + 0.01 * np.eye(precision.shape[0])
                        
                        mahal_squared = diff @ precision @ diff
                        mahal = np.sqrt(np.abs(mahal_squared))
                        
                        if mahal > 100:
                            mahal = np.log1p(mahal)
                        
                    except Exception as e:
                        self.logger.warning(f"Mahalanobis ê³„ì‚° ì‹¤íŒ¨ (class {class_id}): {e}")
                        mahal = np.linalg.norm(diff) * 5  
                else:
                    mahal = np.linalg.norm(diff) * 5
                
                if mahal < min_mahal:
                    min_mahal = mahal
                    best_class = class_id
        
        return min_mahal, best_class
    
    def check_image_quality(self, image):
        """ì´ë¯¸ì§€ í’ˆì§ˆ ê²€ì‚¬"""
        if isinstance(image, np.ndarray):
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        else:
            gray = np.array(image.convert('L'))
        
        # Laplacian varianceë¡œ íë¦¼ ì •ë„ ì¸¡ì •
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        
        # ì—£ì§€ ë°€ë„ ê³„ì‚°
        edges = cv2.Canny(gray, 50, 150)
        edge_density = np.sum(edges > 0) / edges.size
        
        # ì½˜íŠ¸ë¼ìŠ¤íŠ¸ ì¸¡ì •
        contrast = gray.std()
        
        # ResNet50ìš© í’ˆì§ˆ ê¸°ì¤€ (ì•½ê°„ ê´€ëŒ€)
        quality_score = {
            'blur_score': laplacian_var,
            'edge_density': edge_density,
            'contrast': contrast,
            'is_low_quality': laplacian_var < 80 or edge_density < 0.04 or contrast < 25
        }
        
        return quality_score
    
    def predict_single(self, image, debug=False):
        """ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡"""
        quality = self.check_image_quality(image)
        
        if isinstance(image, np.ndarray):
            if len(image.shape) == 2:
                image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
            elif image.shape[2] == 4:
                image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)
            elif image.shape[2] == 3:
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            image = Image.fromarray(image)
        
        image_tensor = self.transform(image).unsqueeze(0).to(self.device)
        
        with torch.no_grad():
            outputs = self.model(image_tensor, return_all=True)
            
            logits = outputs['logits']
            features = outputs['features'].cpu().numpy()[0]
            recon_error = outputs['reconstruction_error'].cpu().item()
            distances = outputs['distances']
            
            probs = F.softmax(logits, dim=1)
            max_prob, predicted_class = probs.max(dim=1)
            max_prob = max_prob.item()
            predicted_class = predicted_class.item()
            
            top2_probs, top2_classes = torch.topk(probs, 2, dim=1)
            confusion_score = (top2_probs[0][0] - top2_probs[0][1]).item()
            
            entropy = -torch.sum(probs * torch.log(probs + 1e-8), dim=1).item()
            min_distance = distances.min(dim=1)[0].item()
            mahal_distance, mahal_class = self.calculate_mahalanobis_distance(features)
            
            if debug:
                print("\n=== ResNet50 ì˜ˆì¸¡ ë””ë²„ê¹… ===")
                print(f"ë°±ë³¸: ResNet50")
                print(f"Temperature: {outputs.get('temperature', 1.5):.3f}")
                
                print("\n=== ì´ë¯¸ì§€ í’ˆì§ˆ ì²´í¬ ===")
                print(f"Blur score: {quality['blur_score']:.2f} (>80 is good)")
                print(f"Edge density: {quality['edge_density']:.3f} (>0.04 is good)")
                print(f"Contrast: {quality['contrast']:.2f} (>25 is good)")
                print(f"Low quality detected: {'âš ï¸ YES' if quality['is_low_quality'] else 'âœ… NO'}")
                
                print("\n=== í˜¼ë™ ê°€ëŠ¥ì„± ì²´í¬ ===")
                print(f"Top 1: {self.known_insects[top2_classes[0][0].item()]} ({top2_probs[0][0]:.3f})")
                print(f"Top 2: {self.known_insects[top2_classes[0][1].item()]} ({top2_probs[0][1]:.3f})")
                print(f"Confusion score: {confusion_score:.3f} (>0.25 is confident)")
                
                print("\n=== ì„ê³„ê°’ ì²´í¬ (ResNet50) ===")
                print(f"Predicted class: {predicted_class} ({self.known_insects[predicted_class]})")
                print(f"Max Prob: {max_prob:.4f} >= {self.thresholds['max_prob']:.4f}? "
                      f"{'âœ…' if max_prob >= self.thresholds['max_prob'] else 'âŒ'}")
                print(f"Entropy: {entropy:.4f} <= {self.thresholds['entropy']:.4f}? "
                      f"{'âœ…' if entropy <= self.thresholds['entropy'] else 'âŒ'}")
                print(f"Min Distance: {min_distance:.4f} <= {self.thresholds['min_distance']:.4f}? "
                      f"{'âœ…' if min_distance <= self.thresholds['min_distance'] else 'âŒ'}")
                print(f"Mahal Distance: {mahal_distance:.4f} <= {self.thresholds.get('mahal_distance', 100):.4f}? "
                      f"{'âœ…' if mahal_distance <= self.thresholds.get('mahal_distance', 100) else 'âŒ'}")
                print(f"Recon Error: {recon_error:.4f} <= {self.thresholds.get('recon_error', 0.12):.4f}? "
                      f"{'âœ…' if recon_error <= self.thresholds.get('recon_error', 0.12) else 'âŒ'}")
            
            # Unknown íŒë‹¨ (ResNet50 ë§ì¶¤)
            is_unknown = False
            rejection_reasons = []
            
            # ì´ë¯¸ì§€ í’ˆì§ˆì´ ë‚®ìœ¼ë©´ ë” ì—„ê²©í•œ ê¸°ì¤€ ì ìš©
            if quality['is_low_quality']:
                adjusted_prob_threshold = min(0.85, self.thresholds['max_prob'] + 0.25)
                if max_prob < adjusted_prob_threshold:
                    is_unknown = True
                    rejection_reasons.append(f"ì €í’ˆì§ˆ ì´ë¯¸ì§€ + ë¶ˆì¶©ë¶„í•œ ì‹ ë¢°ë„: {max_prob:.3f}")
                
                if confusion_score < 0.15:  # ResNet50ìš© ì¡°ì •
                    is_unknown = True
                    rejection_reasons.append(f"ì €í’ˆì§ˆ + í´ë˜ìŠ¤ í˜¼ë™: {confusion_score:.3f}")
            
            # ê¸°ë³¸ ì„ê³„ê°’ ì²´í¬
            if max_prob < self.thresholds['max_prob']:
                is_unknown = True
                rejection_reasons.append(f"ë‚®ì€ ì‹ ë¢°ë„: {max_prob:.3f}")
            
            if entropy > self.thresholds['entropy']:
                is_unknown = True
                rejection_reasons.append(f"ë†’ì€ ì—”íŠ¸ë¡œí”¼: {entropy:.3f}")
            
            if min_distance > self.thresholds['min_distance']:
                is_unknown = True
                rejection_reasons.append(f"í”„ë¡œí† íƒ€ì…ê³¼ ê±°ë¦¬ ë©€ìŒ: {min_distance:.3f}")
            
            if mahal_distance > self.thresholds.get('mahal_distance', 100):
                is_unknown = True
                rejection_reasons.append(f"ë†’ì€ ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬: {mahal_distance:.3f}")
            
            if recon_error > self.thresholds.get('recon_error', 0.12):
                is_unknown = True
                rejection_reasons.append(f"ë†’ì€ ì¬êµ¬ì„± ì˜¤ë¥˜: {recon_error:.6f}")
            
            # ê²°ê³¼ ë°˜í™˜
            if is_unknown:
                return {
                    'class_id': -1,
                    'class_name': 'ë¯¸í™•ì¸ í•´ì¶©',
                    'confidence': max_prob,
                    'is_known': False,
                    'rejection_reasons': rejection_reasons,
                    'quality': quality,
                    'confusion_score': confusion_score,
                    'details': {
                        'max_prob': max_prob,
                        'entropy': entropy,
                        'min_distance': min_distance,
                        'mahal_distance': mahal_distance,
                        'recon_error': recon_error
                    }
                }
            else:
                warning = None
                if quality['is_low_quality'] and max_prob > 0.75:
                    warning = "âš ï¸ ì´ë¯¸ì§€ í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. ë” ì„ ëª…í•œ ì´ë¯¸ì§€ë¡œ ì¬í™•ì¸ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
                
                return {
                    'class_id': predicted_class,
                    'class_name': self.known_insects[predicted_class],
                    'confidence': max_prob,
                    'is_known': True,
                    'warning': warning,
                    'quality': quality,
                    'confusion_score': confusion_score,
                    'rejection_reasons': [],
                    'details': {
                        'max_prob': max_prob,
                        'entropy': entropy,
                        'min_distance': min_distance,
                        'mahal_distance': mahal_distance,
                        'recon_error': recon_error
                    }
                }
    
    def predict_with_tta(self, image, n_augmentations=5, debug=False):
        """Test Time Augmentationìœ¼ë¡œ ì—¬ëŸ¬ ë³€í˜• ì´ë¯¸ì§€ ì˜ˆì¸¡ í›„ ì•™ìƒë¸”"""
        
        predictions = []
        all_probs = []
        
        # ì›ë³¸ ì´ë¯¸ì§€ ì˜ˆì¸¡
        base_result = self.predict_single(image, debug=False)
        predictions.append(base_result)
        
        # PIL Imageë¡œ ë³€í™˜
        if isinstance(image, np.ndarray):
            if len(image.shape) == 2:
                image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
            elif image.shape[2] == 4:
                image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)
            elif image.shape[2] == 3:
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(image)
        else:
            pil_image = image
        
        # TTA transforms
        tta_transforms = [
            transforms.Compose([
                transforms.RandomRotation(degrees=5),
                transforms.Resize(256),
                transforms.CenterCrop(224),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ]),
            transforms.Compose([
                transforms.RandomHorizontalFlip(p=1.0),
                transforms.Resize(256),
                transforms.CenterCrop(224),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ]),
            transforms.Compose([
                transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),
                transforms.Resize(256),
                transforms.CenterCrop(224),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ]),
            transforms.Compose([
                transforms.ColorJitter(brightness=0.1, contrast=0.1),
                transforms.Resize(256),
                transforms.CenterCrop(224),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])
        ]
        
        # ê° ë³€í˜•ì— ëŒ€í•´ ì˜ˆì¸¡
        with torch.no_grad():
            for i, tta_transform in enumerate(tta_transforms[:n_augmentations-1]):
                image_tensor = tta_transform(pil_image).unsqueeze(0).to(self.device)
                
                outputs = self.model(image_tensor, return_all=True)
                logits = outputs['logits']
                probs = F.softmax(logits, dim=1)
                all_probs.append(probs.cpu().numpy()[0])
                
                max_prob, predicted_class = probs.max(dim=1)
                predictions.append({
                    'class_id': predicted_class.item(),
                    'confidence': max_prob.item()
                })
        
        # ì•™ìƒë¸” ê²°ê³¼ ê³„ì‚°
        if all_probs:
            # ì›ë³¸ ì˜ˆì¸¡ì˜ í™•ë¥  ì¶”ê°€
            image_tensor = self.transform(pil_image).unsqueeze(0).to(self.device)
            with torch.no_grad():
                outputs = self.model(image_tensor, return_all=True)
                logits = outputs['logits']
                probs = F.softmax(logits, dim=1)
                all_probs.append(probs.cpu().numpy()[0])
            
            avg_probs = np.mean(all_probs, axis=0)
            std_probs = np.std(all_probs, axis=0)
            
            final_class = np.argmax(avg_probs)
            final_confidence = avg_probs[final_class]
            
            predicted_classes = [p['class_id'] for p in predictions if p.get('class_id', -1) >= 0]
            if predicted_classes:
                consistency = predicted_classes.count(final_class) / len(predicted_classes)
            else:
                consistency = 0
            
            uncertainty = std_probs[final_class]
            
            if debug:
                print("\n=== TTA ì•™ìƒë¸” ê²°ê³¼ (ResNet50) ===")
                print(f"í‰ê·  í™•ë¥ : {final_confidence:.3f}")
                print(f"í‘œì¤€í¸ì°¨: {uncertainty:.3f}")
                print(f"ì¼ê´€ì„±: {consistency:.1%}")
                print(f"ê° augmentation ì˜ˆì¸¡:")
                for i, pred in enumerate(predictions):
                    if pred.get('class_id', -1) >= 0:
                        print(f"  Aug {i}: {self.known_insects.get(pred['class_id'], 'Unknown')} "
                              f"({pred['confidence']:.3f})")
            
            # ìµœì¢… íŒë‹¨ (ResNet50 ë§ì¶¤)
            is_unknown = False
            rejection_reasons = []
            
            # TTA ê¸°ë°˜ ê±°ë¶€ ì¡°ê±´ (ResNet50ìš© ì¡°ì •)
            if final_confidence < 0.65:  # ResNet101ì˜ 0.7ì—ì„œ í•˜í–¥
                is_unknown = True
                rejection_reasons.append(f"TTA í‰ê·  ì‹ ë¢°ë„ ë¶€ì¡±: {final_confidence:.3f}")
            
            if uncertainty > 0.25:  # ResNet101ì˜ 0.2ì—ì„œ ìƒí–¥
                is_unknown = True
                rejection_reasons.append(f"TTA ë¶ˆí™•ì‹¤ì„± ë†’ìŒ: {uncertainty:.3f}")
            
            if consistency < 0.5:  # ResNet101ì˜ 0.6ì—ì„œ í•˜í–¥
                is_unknown = True
                rejection_reasons.append(f"TTA ì¼ê´€ì„± ë¶€ì¡±: {consistency:.1%}")
            
            quality = self.check_image_quality(image)
            if quality['is_low_quality'] and final_confidence < 0.8:
                is_unknown = True
                rejection_reasons.append("ì €í’ˆì§ˆ ì´ë¯¸ì§€ + TTA ì‹ ë¢°ë„ ë¶€ì¡±")
            
            if is_unknown:
                return {
                    'class_id': -1,
                    'class_name': 'ë¯¸í™•ì¸ í•´ì¶©',
                    'confidence': final_confidence,
                    'is_known': False,
                    'rejection_reasons': rejection_reasons,
                    'tta_consistency': consistency,
                    'tta_uncertainty': uncertainty,
                    'quality': quality
                }
            else:
                warning = None
                if quality['is_low_quality']:
                    warning = f"âš ï¸ ì´ë¯¸ì§€ í’ˆì§ˆ ë‚®ìŒ. TTA ì¼ê´€ì„±: {consistency:.1%}"
                elif consistency < 0.7:
                    warning = f"âš ï¸ ì˜ˆì¸¡ ì¼ê´€ì„± ë‚®ìŒ: {consistency:.1%}. ì¬ì´¬ì˜ ê¶Œì¥"
                
                return {
                    'class_id': int(final_class),
                    'class_name': self.known_insects[int(final_class)],
                    'confidence': float(final_confidence),
                    'is_known': True,
                    'warning': warning,
                    'tta_consistency': float(consistency),
                    'tta_uncertainty': float(uncertainty),
                    'quality': quality
                }
        
        return base_result


# ========================
# ë©”ì¸ í…ŒìŠ¤íŠ¸ ì½”ë“œ
# ========================

if __name__ == "__main__":
    import logging
    logging.basicConfig(level=logging.INFO, 
                       format='%(asctime)s - %(levelname)s - %(message)s')
    
    # 1. ëª¨ë¸ ë¡œë“œ
    MODEL_PATH = 'model/improved_model_resnet50.pth'
    
    recognizer = ImprovedOpenSetRecognizer(
        model_path=MODEL_PATH,
        device='cuda' if torch.cuda.is_available() else 'cpu'
    )
    
    # 2. í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ëª©ë¡
    test_images = [
        ('image/test_unknown.jpg', 'ì™„ì „ ì²˜ìŒ ë³´ëŠ” ì´ë¯¸ì§€'),
        ('image/test_image.jpg', 'Test ë°ì´í„°ì…‹ ì´ë¯¸ì§€'),
        ('image/train_image.jpg', 'Train ë°ì´í„°ì…‹ ì´ë¯¸ì§€'),
    ]
    
    # 3. ê° ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸
    for image_path, description in test_images:
        if os.path.exists(image_path):
            print(f"\n{'='*60}")
            print(f"í…ŒìŠ¤íŠ¸: {description} ({image_path})")
            print('='*60)
            
            image = cv2.imread(image_path)
            
            # ì¼ë°˜ ì˜ˆì¸¡ (ë””ë²„ê·¸ ëª¨ë“œ)
            print("\n--- ì¼ë°˜ ì˜ˆì¸¡ (ResNet50) ---")
            result = recognizer.predict_single(image, debug=True)
            
            print(f"\n========== ì˜ˆì¸¡ ê²°ê³¼ ==========")
            print(f"í´ë˜ìŠ¤: {result['class_name']}")
            print(f"ì‹ ë¢°ë„: {result['confidence']:.3f}")
            print(f"Known ì—¬ë¶€: {result['is_known']}")
            
            if result.get('warning'):
                print(f"ê²½ê³ : {result['warning']}")
            
            if not result['is_known']:
                print(f"ê±°ë¶€ ì´ìœ : {', '.join(result['rejection_reasons'])}")
            
            print(f"\nì„¸ë¶€ ì ìˆ˜:")
            for key, value in result['details'].items():
                print(f"  - {key}: {value:.4f}")
            
            # TTA ì˜ˆì¸¡
            print("\n--- TTA ì˜ˆì¸¡ (ResNet50, ë” ì •í™•í•¨) ---")
            tta_result = recognizer.predict_with_tta(image, n_augmentations=5, debug=True)
            
            print(f"\n========== TTA ê²°ê³¼ ==========")
            print(f"í´ë˜ìŠ¤: {tta_result['class_name']}")
            print(f"ì‹ ë¢°ë„: {tta_result['confidence']:.3f}")
            print(f"Known ì—¬ë¶€: {tta_result['is_known']}")
            
            if tta_result.get('warning'):
                print(f"ê²½ê³ : {tta_result['warning']}")
            
            if tta_result.get('tta_consistency') is not None:
                print(f"TTA ì¼ê´€ì„±: {tta_result['tta_consistency']:.1%}")
                print(f"TTA ë¶ˆí™•ì‹¤ì„±: {tta_result.get('tta_uncertainty', 0):.3f}")
            
            if not tta_result['is_known']:
                print(f"ê±°ë¶€ ì´ìœ : {', '.join(tta_result['rejection_reasons'])}")
        else:
            print(f"\nâš ï¸ íŒŒì¼ ì—†ìŒ: {image_path}")