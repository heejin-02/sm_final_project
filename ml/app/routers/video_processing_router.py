"""
ë¹„ë””ì˜¤ ë²„í¼ ì²˜ë¦¬ ë¼ìš°í„° (ëŒ€í‘œ 1ê±´ë§Œ Spring Boot ì „ì†¡ + ì „í™” ë°œì‹  + ë‹¨ì¼ ìŠ¤íŠ¸ë¦¼ í—ˆìš©)
ë¼ì¦ˆë² ë¦¬íŒŒì´ì—ì„œ ë°›ì€ 10ì´ˆê°„ì˜ í”„ë ˆì„(LQ ë‹¨ì¼ ìŠ¤íŠ¸ë¦¼ ë˜ëŠ” LQ+HQ)ì„ ì²˜ë¦¬í•˜ì—¬ í•´ì¶© íƒì§€ ë° ë¶„ë¥˜
"""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
import logging
import base64
import numpy as np
import cv2
from datetime import datetime
from typing import List, Optional
from pathlib import Path
import os
from PIL import ImageFont, ImageDraw, Image

from app.services.yolo_service import YOLOService
from app.services.metadata_service import MetadataService
from app.core.config import settings

logger = logging.getLogger(__name__)
router = APIRouter()

# ----------------------------
# ìš”ì²­/ì‘ë‹µ ëª¨ë¸
# ----------------------------
class VideoBufferRequest(BaseModel):
    type: str = "video_buffer"
    camera_id: str
    gh_idx: int
    recording_start_time: float
    recording_duration: int
    frame_count: int
    lq_frames: List[str]                      # Base64 LQ í”„ë ˆì„ë“¤ (í•„ìˆ˜)
    hq_frames: Optional[List[str]] = None     # Base64 HQ í”„ë ˆì„ë“¤ (ì˜µì…˜: ì—†ìœ¼ë©´ LQë¡œ ëŒ€ì²´)
    timestamps: List[float]
    lq_resolution: List[int]                  # [width, height]
    hq_resolution: Optional[List[int]] = None # [width, height] (ì˜µì…˜: ì—†ìœ¼ë©´ LQë¡œ ëŒ€ì²´)

class VideoProcessingResponse(BaseModel):
    success: bool
    message: str
    camera_id: str
    total_frames: int
    processing_time: float
    detections: Optional[List[dict]] = None

# ----------------------------
# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
# ----------------------------
yolo_service = YOLOService()
metadata_service = MetadataService()

# ----------------------------
# ì—”ë“œí¬ì¸íŠ¸
# ----------------------------
@router.post("/process-video-buffer", response_model=VideoProcessingResponse)
async def process_video_buffer(request: VideoBufferRequest):
    """
    10ì´ˆê°„ì˜ ë¹„ë””ì˜¤ ë²„í¼ë¥¼ ì²˜ë¦¬í•˜ì—¬ í•´ì¶© íƒì§€ ë° í¬ë¡­ ìƒì„±/ì €ì¥, ì‹œê°í™” ë¹„ë””ì˜¤ ì—…ë¡œë“œ,
    ëŒ€í‘œ íƒì§€ 1ê±´ ì „ì†¡ ë° ì „í™” ë°œì‹ .
    """
    start_time = datetime.now()

    try:
        logger.info(f"ğŸ¬ ë¹„ë””ì˜¤ ë²„í¼ ì²˜ë¦¬ ì‹œì‘: camera_id={request.camera_id}, frames={request.frame_count}")

        # ----------------------------
        # ì…ë ¥ ì •ê·œí™”
        # ----------------------------
        lq_frames = request.lq_frames or []
        hq_frames = request.hq_frames or []
        timestamps = request.timestamps or []

        if len(lq_frames) == 0:
            raise HTTPException(status_code=400, detail="LQ í”„ë ˆì„ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤")

        # ë‹¨ì¼ ìŠ¤íŠ¸ë¦¼ í—ˆìš©: HQ ì—†ìœ¼ë©´ LQ ì¬ì‚¬ìš©
        if not hq_frames:
            logger.info("ë‹¨ì¼ ìŠ¤íŠ¸ë¦¼ ëª¨ë“œ ê°ì§€: HQ í”„ë ˆì„ì´ ì—†ì–´ LQë¥¼ HQë¡œ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.")
            hq_frames = lq_frames
            if not request.hq_resolution:
                request.hq_resolution = request.lq_resolution

        # ê¸°ì¤€ í”„ë ˆì„ ìˆ˜ ë³´ì •
        n = len(lq_frames)
        if request.frame_count != n:
            logger.warning(f"frame_count({request.frame_count}) â‰  ì‹¤ì œ LQ ê¸¸ì´({n}) â†’ ë³´ì •")
        request.frame_count = n

        # ê¸¸ì´ ë¶ˆì¼ì¹˜ ì‹œ ê°€ì¥ ì§§ì€ ê¸¸ì´ë¡œ ì ˆë‹¨
        if len(hq_frames) != n or len(timestamps) != n:
            m = min(n, len(hq_frames), len(timestamps))
            if m == 0:
                raise HTTPException(status_code=400, detail="í”„ë ˆì„/íƒ€ì„ìŠ¤íƒ¬í”„ ê¸¸ì´ê°€ 0ì…ë‹ˆë‹¤")
            if len(hq_frames) != n:
                logger.warning(f"HQ ê¸¸ì´({len(hq_frames)}) â‰  LQ ê¸¸ì´({n}) â†’ {m}ìœ¼ë¡œ ë³´ì •")
            if len(timestamps) != n:
                logger.warning(f"timestamps ê¸¸ì´({len(timestamps)}) â‰  LQ ê¸¸ì´({n}) â†’ {m}ìœ¼ë¡œ ë³´ì •")
            lq_frames, hq_frames, timestamps = lq_frames[:m], hq_frames[:m], timestamps[:m]
            request.frame_count = m

        # ----------------------------
        # í”„ë ˆì„ ì²˜ë¦¬ ë£¨í”„
        # ----------------------------
        all_detections: List[dict] = []
        annotated_hq_frames: List[Optional[np.ndarray]] = []
        processed_frames = 0

        for i in range(request.frame_count):
            lq_b64 = lq_frames[i]
            hq_b64 = hq_frames[i]
            ts = timestamps[i]

            try:
                # ë””ì½”ë”©
                hq_frame = decode_base64_frame(hq_b64)
                if hq_frame is None:
                    logger.warning(f"HQ í”„ë ˆì„ {i} ë””ì½”ë”© ì‹¤íŒ¨")
                    annotated_hq_frames.append(None)
                    continue

                lq_frame = decode_base64_frame(lq_b64)
                if lq_frame is None:
                    logger.warning(f"LQ í”„ë ˆì„ {i} ë””ì½”ë”© ì‹¤íŒ¨")
                    annotated_hq_frames.append(hq_frame.copy())
                    continue

                # YOLO íƒì§€ (LQ ê¸°ì¤€)
                detections = await yolo_service.detect_insects(lq_frame)

                # HQ ì‹œê°í™” í”„ë ˆì„ ìƒì„±
                annotated_hq = draw_detections_on_hq_frame(
                    detections, lq_frame, hq_frame
                ) if detections else hq_frame.copy()
                annotated_hq_frames.append(annotated_hq)

                # ë©”íƒ€/í¬ë¡­ ì €ì¥
                if detections:
                    frame_detections = await process_detections_with_hq_sync(
                        detections, lq_frame, hq_frame, request, ts, i
                    )
                    all_detections.extend(frame_detections)

                processed_frames += 1

                if i % 20 == 0:
                    logger.info(f"ì²˜ë¦¬ ì§„í–‰: {i+1}/{request.frame_count} ({((i+1)/request.frame_count)*100:.1f}%)")

            except Exception as e:
                logger.error(f"í”„ë ˆì„ {i} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue

        # ----------------------------
        # ì‹œê°í™” ë¹„ë””ì˜¤ ìƒì„± â†’ Spring Boot ì „ì†¡
        # ----------------------------
        video_path, img_idx = None, None
        if annotated_hq_frames:
            video_path = await create_annotated_video(annotated_hq_frames, request)
            if video_path:
                img_idx = await send_video_to_spring_boot(video_path, request, len(all_detections))
                # ëŒ€í‘œ 1ê±´ë§Œ ì „ì†¡ + ì „í™” ë°œì‹ 
                if img_idx and all_detections:
                    await send_all_detections_to_spring_boot(all_detections, request.gh_idx, img_idx)

        # ----------------------------
        # ì‘ë‹µ
        # ----------------------------
        processing_time = (datetime.now() - start_time).total_seconds()
        logger.info(
            f"âœ… ë¹„ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ: {processed_frames}/{request.frame_count}í”„ë ˆì„, "
            f"{len(all_detections)}ê°œ íƒì§€, {processing_time:.2f}ì´ˆ ì†Œìš”"
        )

        return VideoProcessingResponse(
            success=True,
            message=f"{len(all_detections)}ê°œ í•´ì¶© íƒì§€ ì™„ë£Œ, ë¹„ë””ì˜¤ ìƒì„±: {video_path}",
            camera_id=request.camera_id,
            total_frames=processed_frames,
            processing_time=processing_time,
            detections=all_detections
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"Video processing failed: {str(e)}")

# ----------------------------
# í—¬í¼ í•¨ìˆ˜ë“¤
# ----------------------------
async def process_detections_with_hq_sync(
    detections, lq_frame, hq_frame, request: VideoBufferRequest, timestamp, frame_idx
):
    """
    LQì—ì„œ íƒì§€ëœ ê²°ê³¼ë¥¼ HQ ì¢Œí‘œê³„ë¡œ ë³€í™˜í•˜ì—¬ í¬ë¡­ ì´ë¯¸ì§€ ì €ì¥ ë° ë©”íƒ€ë°ì´í„° ê¸°ë¡
    """
    frame_detections: List[dict] = []

    lq_h, lq_w = lq_frame.shape[:2]
    hq_h, hq_w = hq_frame.shape[:2]
    scale_x, scale_y = hq_w / max(1, lq_w), hq_h / max(1, lq_h)

    for det in detections:
        try:
            lq_bbox = det["bbox"]  # [x_min, y_min, x_max, y_max]
            hq_bbox = [
                int(lq_bbox[0] * scale_x),
                int(lq_bbox[1] * scale_y),
                int(lq_bbox[2] * scale_x),
                int(lq_bbox[3] * scale_y),
            ]
            # ê²½ê³„ ë³´ì •
            hq_bbox[0] = max(0, min(hq_bbox[0], hq_w - 1))
            hq_bbox[1] = max(0, min(hq_bbox[1], hq_h - 1))
            hq_bbox[2] = max(hq_bbox[0] + 1, min(hq_bbox[2], hq_w))
            hq_bbox[3] = max(hq_bbox[1] + 1, min(hq_bbox[3], hq_h))

            cropped_hq = hq_frame[hq_bbox[1]:hq_bbox[3], hq_bbox[0]:hq_bbox[2]]
            if cropped_hq.size == 0:
                logger.warning(f"í¬ë¡­ ì˜ì—­ì´ ë¹„ì–´ìˆìŒ: {hq_bbox}")
                continue

            # ë©”íƒ€ ì €ì¥
            metadata = await metadata_service.save_detection_metadata(
                camera_id=request.camera_id,
                gh_idx=request.gh_idx,
                insect_name=det["class_name"],
                confidence=det["confidence"],
                bbox=hq_bbox,
                timestamp=timestamp
            )

            # í¬ë¡­ ì €ì¥
            crop_path = await save_cropped_image(
                request.camera_id, cropped_hq, metadata["rec_id"],
                metadata["track_id"], frame_idx, det["class_name"]
            )

            frame_detections.append({
                "class_name": det["class_name"],
                "confidence": det["confidence"],
                "lq_bbox": lq_bbox,
                "hq_bbox": hq_bbox,
                "rec_id": metadata["rec_id"],
                "track_id": metadata["track_id"],
                "crop_path": crop_path,
                "frame_index": frame_idx,
                "timestamp": timestamp
            })

        except Exception as e:
            logger.error(f"íƒì§€ ê²°ê³¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            continue

    return frame_detections


def decode_base64_frame(base64_data: str) -> Optional[np.ndarray]:
    """Base64 â†’ OpenCV ì´ë¯¸ì§€"""
    try:
        img_data = base64.b64decode(base64_data)
        nparr = np.frombuffer(img_data, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        return frame
    except Exception as e:
        logger.error(f"í”„ë ˆì„ ë””ì½”ë”© ì˜¤ë¥˜: {e}")
        return None


async def save_cropped_image(
    camera_id: str, cropped_frame: np.ndarray, rec_id: int, track_id: int, frame_idx: int, class_name: str
) -> str:
    """í¬ë¡­ëœ HQ ì´ë¯¸ì§€ ì €ì¥"""
    save_dir = Path("data/cropped_detections") / camera_id / class_name
    save_dir.mkdir(parents=True, exist_ok=True)

    filename = f"rec{rec_id}_track{track_id}_frame{frame_idx}_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}.jpg"
    filepath = save_dir / filename
    cv2.imwrite(str(filepath), cropped_frame)
    return str(filepath)


async def send_detection_to_spring_boot(
    insect_name: str, confidence: float, crop_path: str, gh_idx: int, img_idx: int = None
):
    """ëŒ€í‘œ íƒì§€ 1ê±´ ì „ì†¡"""
    import requests

    payload = {
        "anlsModel": "YOLOv5",
        "anlsContent": f"{insect_name} {confidence * 100:.2f}%ë¡œ íƒì§€ì™„ë£Œ",
        "anlsResult": insect_name,
        "createdAt": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "insectIdx": {"ê½ƒë…¸ë‘ì´ì±„ë²Œë ˆ": 1, "ë‹´ë°°ê°€ë£¨ì´": 2, "ë¹„ë‹¨ë…¸ë¦°ì¬": 3, "ì•Œë½ìˆ˜ì—¼ë…¸ë¦°ì¬": 4}.get(insect_name, 0),
        "imgIdx": img_idx if img_idx else 1,
        "notiCheck": 'N',
        "ghIdx": gh_idx,
        "anlsAcc": int(confidence * 100),
    }

    try:
        spring_boot_url = os.getenv("SPRING_BOOT_URL", "http://localhost:8095")
        res = requests.post(f"{spring_boot_url}/api/qc-classification", json=payload, timeout=10)
        logger.info(f"Spring Boot ì „ì†¡ ì™„ë£Œ: {insect_name} | ìƒíƒœ: {res.status_code}")
    except Exception as e:
        logger.error(f"Spring Boot ì „ì†¡ ì‹¤íŒ¨: {e}")


def draw_text_korean(img, text, org, font_size=20, color=(0, 0, 0)):
    """ì´ë¯¸ì§€ì— í•œê¸€ í…ìŠ¤íŠ¸ ì¶œë ¥ (PIL ì‚¬ìš©, í°íŠ¸ ê²½ë¡œ í´ë°± ì§€ì›)"""
    try:
        # í™˜ê²½ë³€ìˆ˜ ìš°ì„  â†’ ë¦¬ëˆ…ìŠ¤ ë‚˜ëˆ”ê³ ë”• â†’ ë§¥ â†’ ìœˆë„ìš° â†’ ì‹¤íŒ¨ ì‹œ OpenCV í´ë°±
        candidates = [
            os.getenv("KOREAN_FONT_PATH"),
            "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
            "/Library/Fonts/AppleGothic.ttf",
            "C:/Windows/Fonts/NanumGothic.ttf",
            "C:/Windows/Fonts/malgun.ttf",
        ]
        font_path = next((p for p in candidates if p and os.path.exists(p)), None)
        if not font_path:
            raise FileNotFoundError("í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        font = ImageFont.truetype(font_path, font_size)
        img_pil = Image.fromarray(img)
        draw = ImageDraw.Draw(img_pil)
        draw.text(org, text, font=font, fill=color)
        return np.array(img_pil)

    except Exception as e:
        logger.warning(f"í•œê¸€ í…ìŠ¤íŠ¸ ì¶œë ¥ ì˜¤ë¥˜(ê¸°ë³¸ í°íŠ¸ë¡œ ëŒ€ì²´): {e}")
        cv2.putText(img, text, org, cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2, cv2.LINE_AA)
        return img


def draw_detections_on_hq_frame(
    detections: List[dict],
    lq_frame: np.ndarray,
    hq_frame: np.ndarray,
    convert_to_rgb: bool = False
) -> np.ndarray:
    """
    HQ í”„ë ˆì„ì— LQì—ì„œ íƒì§€ëœ ë°”ìš´ë”©ë°•ìŠ¤ë¥¼ ì‹œê°í™”
    """
    annotated = hq_frame.copy()

    # í•´ìƒë„ ë¹„ìœ¨(LQ â†’ HQ)
    lq_h, lq_w = lq_frame.shape[:2]
    hq_h, hq_w = hq_frame.shape[:2]
    scale_x, scale_y = hq_w / max(1, lq_w), hq_h / max(1, lq_h)

    # ê³¤ì¶©ë³„ ìƒ‰ìƒ
    colors = {
        "ê½ƒë…¸ë‘ì´ì±„ë²Œë ˆ": (0, 255, 255),  # ë…¸ë‘
        "ë‹´ë°°ê°€ë£¨ì´": (255, 255, 255),    # í•˜ì–‘
        "ë¹„ë‹¨ë…¸ë¦°ì¬": (0, 255, 0),        # ì´ˆë¡
        "ì•Œë½ìˆ˜ì—¼ë…¸ë¦°ì¬": (255, 0, 0),     # ë¹¨ê°•
    }

    for det in detections:
        bbox = det["bbox"]  # [x_min, y_min, x_max, y_max]
        x1 = int(bbox[0] * scale_x)
        y1 = int(bbox[1] * scale_y)
        x2 = int(bbox[2] * scale_x)
        y2 = int(bbox[3] * scale_y)

        # ê²½ê³„ ë³´ì •
        x1, y1 = max(0, x1), max(0, y1)
        x2, y2 = min(hq_w - 1, x2), min(hq_h - 1, y2)

        class_name = det["class_name"]
        conf = det["confidence"]
        color = colors.get(class_name, (0, 255, 0))

        # ë°•ìŠ¤
        cv2.rectangle(annotated, (x1, y1), (x2, y2), color, 3)

        # ë ˆì´ë¸” ë°°ê²½
        label = f"{class_name} {conf:.2f}"
        (lw, lh), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)
        cv2.rectangle(annotated, (x1, y1 - lh - 10), (x1 + lw + 10, y1), color, -1)

        # í•œê¸€ í…ìŠ¤íŠ¸
        annotated = draw_text_korean(annotated, label, (x1 + 5, y1 - 25), font_size=20, color=(0, 0, 0))

    if convert_to_rgb:
        annotated = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)

    return annotated


async def create_annotated_video(
    annotated_frames: List[Optional[np.ndarray]], request: VideoBufferRequest
) -> Optional[str]:
    """
    ì‹œê°í™”ëœ í”„ë ˆì„ë“¤ë¡œ MP4(H.264 ìš°ì„ ) ë¹„ë””ì˜¤ ìƒì„±
    """
    try:
        video_dir = Path("data/processed_videos") / request.camera_id
        video_dir.mkdir(parents=True, exist_ok=True)

        ts = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        video_path = video_dir / f"detection_{request.camera_id}_{ts}.mp4"

        # ìœ íš¨ í”„ë ˆì„ ì°¾ê¸°
        valid = next((f for f in annotated_frames if f is not None), None)
        if valid is None:
            logger.error("ìœ íš¨í•œ í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤")
            return None

        height, width = valid.shape[:2]
        # FPS ì¶”ì •: frame_count / duration (1~30 ì‚¬ì´ clamp)
        est_fps = int(round(max(1.0, min(30.0, request.frame_count / max(1e-3, request.recording_duration)))))
        fps = est_fps if est_fps > 0 else 10

        # imageio-ffmpeg ìš°ì„ (H.264)
        try:
            import imageio
            logger.info("ğŸ¬ imageio-ffmpegë¥¼ ì‚¬ìš©í•˜ì—¬ H.264 ë¹„ë””ì˜¤ ìƒì„± ì‹œì‘")

            rgb_frames = []
            for i, frame in enumerate(annotated_frames):
                if frame is None:
                    # ë¹ˆ í”„ë ˆì„ â†’ ì§ì „ í”„ë ˆì„ ë˜ëŠ” valid
                    frame = annotated_frames[i-1] if i > 0 and annotated_frames[i-1] is not None else valid
                if frame.shape[:2] != (height, width):
                    frame = cv2.resize(frame, (width, height))
                rgb_frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

            # macro_block_size=16 (ê¸°ë³¸) â†’ ì¼ë¶€ í•´ìƒë„ëŠ” ë‚´ë¶€ì—ì„œ íŒ¨ë”©ë  ìˆ˜ ìˆìŒ(ê²½ê³  ë¡œê·¸ ì •ìƒ)
            imageio.mimwrite(
                str(video_path),
                rgb_frames,
                fps=fps,
                codec='libx264',
                pixelformat='yuv420p',
                macro_block_size=16,
            )
            logger.info(f"âœ… imageio-ffmpegë¡œ H.264 ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {video_path}")
            return str(video_path)

        except ImportError:
            logger.warning("âš ï¸ imageio-ffmpeg ë¯¸ì„¤ì¹˜. OpenCV mp4v ì½”ë±ìœ¼ë¡œ í´ë°±í•©ë‹ˆë‹¤.")
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(str(video_path), fourcc, fps, (width, height))
            if not out.isOpened():
                logger.error("VideoWriter ì—´ê¸° ì‹¤íŒ¨")
                return None

            for i, frame in enumerate(annotated_frames):
                if frame is None:
                    frame = annotated_frames[i-1] if i > 0 and annotated_frames[i-1] is not None else valid
                if frame.shape[:2] != (height, width):
                    frame = cv2.resize(frame, (width, height))
                out.write(frame)
            out.release()

            logger.info(f"âœ… ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {video_path} (mp4v)")
            logger.warning("âš ï¸ mp4v ì½”ë±ì€ ì¼ë¶€ ë¸Œë¼ìš°ì €ì—ì„œ ì¬ìƒ í˜¸í™˜ì„±ì´ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return str(video_path)

    except Exception as e:
        logger.error(f"âŒ ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {e}")
        return None


async def send_video_to_spring_boot(
    video_path: str, request: VideoBufferRequest, detection_count: int
) -> Optional[int]:
    """
    ìƒì„±ëœ ë¹„ë””ì˜¤ë¥¼ Spring Boot ì„œë²„ë¡œ ì—…ë¡œë“œí•˜ê³  IMG_IDX ë°˜í™˜
    """
    import requests

    try:
        if not Path(video_path).exists():
            logger.error(f"ë¹„ë””ì˜¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {video_path}")
            return None

        base_url = os.getenv("SPRING_BOOT_URL", "http://localhost:8095")
        spring_boot_url = f"{base_url}/api/video/upload"

        with open(video_path, 'rb') as video_file:
            files = {'video': (Path(video_path).name, video_file, 'video/mp4')}
            data = {
                'camera_id': request.camera_id,
                'gh_idx': request.gh_idx,
                'detection_count': detection_count,
                'recording_start_time': request.recording_start_time,
                'frame_count': request.frame_count
            }
            res = requests.post(spring_boot_url, files=files, data=data, timeout=30)

        if res.status_code == 200:
            result = res.json()
            img_idx = result.get('img_idx')
            logger.info(f"âœ… Spring Boot ë¹„ë””ì˜¤ ì „ì†¡ ì„±ê³µ: {video_path}, IMG_IDX: {img_idx}")
            return img_idx
        else:
            logger.error(f"âŒ Spring Boot ë¹„ë””ì˜¤ ì „ì†¡ ì‹¤íŒ¨: {res.status_code} | {res.text}")
            return None

    except Exception as e:
        logger.error(f"âŒ Spring Boot ë¹„ë””ì˜¤ ì „ì†¡ ì˜¤ë¥˜: {e}")
        return None


async def send_all_detections_to_spring_boot(detections: List[dict], gh_idx: int, img_idx: int):
    """
    ëˆ„ì ëœ íƒì§€ë“¤ ì¤‘ 'ëŒ€í‘œ 1ê±´(ìµœê³  ì‹ ë¢°ë„)'ë§Œ ì „ì†¡í•˜ê³  ì „í™” ë°œì‹ 
    """
    try:
        if not detections:
            logger.info("íƒì§€ ê²°ê³¼ ì—†ìŒ â†’ ì „ì†¡ ìƒëµ")
            return
        best = max(detections, key=lambda x: x["confidence"])
        await send_detection_to_spring_boot(
            best["class_name"], best["confidence"], best["crop_path"], gh_idx, img_idx
        )
        logger.info(f"ëŒ€í‘œ íƒì§€ ì „ì†¡ ì™„ë£Œ: {best['class_name']} ({best['confidence']:.2f})")

        # ì „í™” ë°œì‹ 
        await make_call(gh_idx, best["class_name"], best["confidence"])

    except Exception as e:
        logger.error(f"âŒ ëŒ€í‘œ íƒì§€ ì „ì†¡ ì‹¤íŒ¨: {e}")


async def make_call(gh_idx: int, insect_name: str, confidence: float):
    """ì „í™” ë°œì‹ """
    import requests
    try:
        ml_api_url = os.getenv("ML_API_URL", "http://localhost:8003/api/make-call")
        params = {
            "gh_idx": gh_idx,
            "insect_name": insect_name,
            "confidence": confidence
        }
        res = requests.post(ml_api_url, params=params, timeout=10)
        if res.status_code == 200:
            logger.info(f"ì „í™” ë°œì‹  ì„±ê³µ: {insect_name} (ì‹ ë¢°ë„ {confidence:.2f})")
        else:
            logger.error(f"ì „í™” ë°œì‹  ì‹¤íŒ¨: {res.status_code} | {res.text}")
    except Exception as e:
        logger.error(f"ì „í™” ë°œì‹  ì˜¤ë¥˜: {e}")
