"""
ë¹„ë””ì˜¤ ë²„í¼ ì²˜ë¦¬ ë¼ìš°í„°
ë¼ì¦ˆë² ë¦¬íŒŒì´ì—ì„œ ë°›ì€ 10ì´ˆê°„ì˜ LQ+HQ í”„ë ˆì„ì„ ì²˜ë¦¬í•˜ì—¬ í•´ì¶© íƒì§€ ë° ë¶„ë¥˜
"""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
import logging
import base64
import numpy as np
import cv2
from datetime import datetime
from typing import List, Optional
import asyncio

from app.services.yolo_service import YOLOService
from app.services.metadata_service import MetadataService

logger = logging.getLogger(__name__)

router = APIRouter()

class VideoBufferRequest(BaseModel):
    type: str = "video_buffer"
    camera_id: str
    gh_idx: int
    recording_start_time: float
    recording_duration: int
    frame_count: int
    lq_frames: List[str]  # Base64 ì¸ì½”ë”©ëœ LQ í”„ë ˆì„ë“¤
    hq_frames: List[str]  # Base64 ì¸ì½”ë”©ëœ HQ í”„ë ˆì„ë“¤
    timestamps: List[float]
    lq_resolution: List[int]
    hq_resolution: List[int]

class VideoProcessingResponse(BaseModel):
    success: bool
    message: str
    camera_id: str
    total_frames: int
    processing_time: float
    detections: Optional[List[dict]] = None

# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ë“¤
yolo_service = YOLOService()
metadata_service = MetadataService()

@router.post("/process-video-buffer", response_model=VideoProcessingResponse)
async def process_video_buffer(request: VideoBufferRequest):
    """
    10ì´ˆê°„ì˜ ë¹„ë””ì˜¤ ë²„í¼ë¥¼ ì²˜ë¦¬í•˜ì—¬ í•´ì¶© íƒì§€ ë° í¬ë¡­ ì´ë¯¸ì§€ ìƒì„±
    """
    start_time = datetime.now()
    
    try:
        logger.info(f"ğŸ¬ ë¹„ë””ì˜¤ ë²„í¼ ì²˜ë¦¬ ì‹œì‘: camera_id={request.camera_id}, frames={request.frame_count}")
        
        # í”„ë ˆì„ ìˆ˜ ê²€ì¦
        if len(request.lq_frames) != len(request.hq_frames):
            raise HTTPException(status_code=400, detail="LQì™€ HQ í”„ë ˆì„ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
        
        if len(request.lq_frames) != request.frame_count:
            raise HTTPException(status_code=400, detail="í”„ë ˆì„ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
        
        # ëª¨ë“  íƒì§€ ê²°ê³¼ ë° ì‹œê°í™”ëœ í”„ë ˆì„ ì €ì¥
        all_detections = []
        annotated_hq_frames = []  # YOLO ê²°ê³¼ê°€ ê·¸ë ¤ì§„ HQ í”„ë ˆì„ë“¤
        processed_frames = 0
        
        # í”„ë ˆì„ë³„ ì²˜ë¦¬
        for i, (lq_b64, hq_b64, timestamp) in enumerate(zip(request.lq_frames, request.hq_frames, request.timestamps)):
            try:
                # HQ í”„ë ˆì„ ë””ì½”ë”© (ë§¨ ë¨¼ì € ë””ì½”ë”©)
                hq_frame = decode_base64_frame(hq_b64)
                if hq_frame is None:
                    logger.warning(f"HQ í”„ë ˆì„ {i} ë””ì½”ë”© ì‹¤íŒ¨")
                    # ë¹ˆ í”„ë ˆì„ì´ë¼ë„ ì €ì¥ (ë¹„ë””ì˜¤ ë™ê¸°í™”ë¥¼ ìœ„í•´)
                    annotated_hq_frames.append(None)
                    continue
                
                # LQ í”„ë ˆì„ ë””ì½”ë”©
                lq_frame = decode_base64_frame(lq_b64)
                if lq_frame is None:
                    logger.warning(f"LQ í”„ë ˆì„ {i} ë””ì½”ë”© ì‹¤íŒ¨")
                    # HQ í”„ë ˆì„ë§Œ ì €ì¥ (íƒì§€ ê²°ê³¼ ì—†ìŒ)
                    annotated_hq_frames.append(hq_frame.copy())
                    continue
                
                # LQ í”„ë ˆì„ì—ì„œ YOLO íƒì§ ìˆ˜í–‰
                detections = await yolo_service.detect_insects(lq_frame)
                
                # HQ í”„ë ˆì„ì— íƒì§ ê²°ê³¼ ì‹œê°í™”
                annotated_hq = draw_detections_on_hq_frame(detections, lq_frame, hq_frame) if detections else hq_frame.copy()
                annotated_hq_frames.append(annotated_hq)
                
                if detections:
                    # íƒì§ ê²°ê³¼ë¥¼ HQ í”„ë ˆì„ê³¼ ë™ê¸°í™”í•˜ì—¬ ì²˜ë¦¬
                    frame_detections = await process_detections_with_hq_sync(
                        detections, lq_frame, hq_frame, request, timestamp, i
                    )
                    
                    all_detections.extend(frame_detections)
                    
                    logger.info(f"í”„ë ˆì„ {i}/{request.frame_count}: {len(detections)}ê°œ íƒì§")
                
                processed_frames += 1
                
                # ì§„í–‰ìƒí™© ë¡œê¹… (20í”„ë ˆì„ë§ˆë‹¤)
                if i % 20 == 0:
                    logger.info(f"ì²˜ë¦¬ ì§„í–‰: {i+1}/{request.frame_count} ({((i+1)/request.frame_count)*100:.1f}%)")
                
            except Exception as e:
                logger.error(f"í”„ë ˆì„ {i} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        # YOLO ê²°ê³¼ê°€ ê·¸ë ¤ì§„ HQ ë¹„ë””ì˜¤ ìƒì„± ë° Spring Bootë¡œ ì „ì†¡
        video_path = None
        if len(annotated_hq_frames) > 0:
            video_path = await create_annotated_video(annotated_hq_frames, request)
            if video_path:
                # Spring Bootë¡œ ë¹„ë””ì˜¤ ì „ì†¡
                await send_video_to_spring_boot(video_path, request, len(all_detections))
        
        # ì²˜ë¦¬ ì™„ë£Œ
        processing_time = (datetime.now() - start_time).total_seconds()
        
        logger.info(f"âœ… ë¹„ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ: {processed_frames}/{request.frame_count}í”„ë ˆì„, "
                   f"{len(all_detections)}ê°œ íƒì§, {processing_time:.2f}ì´ˆ ì†Œìš”")
        
        return VideoProcessingResponse(
            success=True,
            message=f"{len(all_detections)}ê°œ í•´ì¶© íƒì§ ì™„ë£Œ, ë¹„ë””ì˜¤ ìƒì„±: {video_path}",
            camera_id=request.camera_id,
            total_frames=processed_frames,
            processing_time=processing_time,
            detections=all_detections
        )
        
    except Exception as e:
        processing_time = (datetime.now() - start_time).total_seconds()
        logger.error(f"âŒ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"Video processing failed: {str(e)}")

async def process_detections_with_hq_sync(detections, lq_frame, hq_frame, request, timestamp, frame_idx):
    """
    LQì—ì„œ íƒì§€ëœ ê²°ê³¼ë¥¼ HQ í”„ë ˆì„ê³¼ ë™ê¸°í™”í•˜ì—¬ í¬ë¡­ ì´ë¯¸ì§€ ìƒì„±
    """
    frame_detections = []
    
    # í•´ìƒë„ ë¹„ìœ¨ ê³„ì‚° (LQ â†’ HQ ìŠ¤ì¼€ì¼ë§)
    lq_h, lq_w = lq_frame.shape[:2]
    hq_h, hq_w = hq_frame.shape[:2]
    
    scale_x = hq_w / lq_w
    scale_y = hq_h / lq_h
    
    for detection in detections:
        try:
            # LQ bboxë¥¼ HQ ì¢Œí‘œê³„ë¡œ ë³€í™˜
            lq_bbox = detection["bbox"]  # [x_min, y_min, x_max, y_max]
            
            hq_bbox = [
                int(lq_bbox[0] * scale_x),  # x_min
                int(lq_bbox[1] * scale_y),  # y_min  
                int(lq_bbox[2] * scale_x),  # x_max
                int(lq_bbox[3] * scale_y)   # y_max
            ]
            
            # ê²½ê³„ ê²€ì‚¬
            hq_bbox[0] = max(0, min(hq_bbox[0], hq_w-1))
            hq_bbox[1] = max(0, min(hq_bbox[1], hq_h-1))
            hq_bbox[2] = max(hq_bbox[0]+1, min(hq_bbox[2], hq_w))
            hq_bbox[3] = max(hq_bbox[1]+1, min(hq_bbox[3], hq_h))
            
            # HQ í”„ë ˆì„ì—ì„œ í¬ë¡­
            cropped_hq = hq_frame[hq_bbox[1]:hq_bbox[3], hq_bbox[0]:hq_bbox[2]]
            
            if cropped_hq.size == 0:
                logger.warning(f"í¬ë¡­ ì˜ì—­ì´ ë¹„ì–´ìˆìŒ: {hq_bbox}")
                continue
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            metadata = await metadata_service.save_detection_metadata(
                camera_id=request.camera_id,
                gh_idx=request.gh_idx,
                insect_name=detection["class_name"],
                confidence=detection["confidence"],
                bbox=hq_bbox,
                timestamp=timestamp
            )
            
            # í¬ë¡­ ì´ë¯¸ì§€ ì €ì¥
            crop_path = await save_cropped_image(
                request.camera_id, cropped_hq, metadata["rec_id"], 
                metadata["track_id"], frame_idx, detection["class_name"]
            )
            
            # Spring Bootë¡œ ê²°ê³¼ ì „ì†¡
            await send_detection_to_spring_boot(
                detection["class_name"], detection["confidence"], crop_path, request.gh_idx
            )
            
            frame_detections.append({
                "class_name": detection["class_name"],
                "confidence": detection["confidence"],
                "lq_bbox": lq_bbox,
                "hq_bbox": hq_bbox,
                "rec_id": metadata["rec_id"],
                "track_id": metadata["track_id"],
                "crop_path": crop_path,
                "frame_index": frame_idx,
                "timestamp": timestamp
            })
            
        except Exception as e:
            logger.error(f"íƒì§€ ê²°ê³¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            continue
    
    return frame_detections

def decode_base64_frame(base64_data: str) -> Optional[np.ndarray]:
    """Base64 ë°ì´í„°ë¥¼ OpenCV í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜"""
    try:
        img_data = base64.b64decode(base64_data)
        nparr = np.frombuffer(img_data, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        return frame
    except Exception as e:
        logger.error(f"í”„ë ˆì„ ë””ì½”ë”© ì˜¤ë¥˜: {e}")
        return None

async def save_cropped_image(camera_id: str, cropped_frame: np.ndarray, 
                            rec_id: int, track_id: int, frame_idx: int, class_name: str) -> str:
    """í¬ë¡­ëœ ê³ í•´ìƒë„ ì´ë¯¸ì§€ ì €ì¥"""
    from pathlib import Path
    
    # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„± (ê³¤ì¶© ì¢…ë¥˜ë³„ë¡œ ë¶„ë¥˜)
    save_dir = Path("data/cropped_detections") / camera_id / class_name
    save_dir.mkdir(parents=True, exist_ok=True)
    
    # íŒŒì¼ëª… ìƒì„±
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    filename = f"rec{rec_id}_track{track_id}_frame{frame_idx}_{timestamp}.jpg"
    filepath = save_dir / filename
    
    # ì´ë¯¸ì§€ ì €ì¥
    cv2.imwrite(str(filepath), cropped_frame)
    
    return str(filepath)

async def send_detection_to_spring_boot(insect_name: str, confidence: float, 
                                      crop_path: str, gh_idx: int):
    """Spring Boot APIë¡œ íƒì§€ ê²°ê³¼ ì „ì†¡"""
    import requests
    
    def get_insect_idx(name):
        return {
            "ê½ƒë…¸ë‘ì´ì±„ë²Œë ˆ": 1,
            "ë‹´ë°°ê°€ë£¨ì´": 2,
            "ë¹„ë‹¨ë…¸ë¦°ì¬": 3,
            "ì•Œë½ìˆ˜ì—¼ë…¸ë¦°ì¬": 4
        }.get(name, 0)
    
    now = datetime.now()
    created_at = now.strftime("%Y-%m-%d %H:%M:%S")
    
    payload = {
        "anlsModel": "YOLOv5",
        "anlsContent": f"{insect_name} {confidence * 100:.2f}%ë¡œ íƒì§€ì™„ë£Œ",
        "anlsResult": insect_name,
        "createdAt": created_at,
        "insectIdx": get_insect_idx(insect_name),
        "imgIdx": 1,
        "notiCheck": 'N',
        "ghIdx": gh_idx,
        "anlsAcc": int(confidence * 100)
    }
    
    try:
        res = requests.post("http://localhost:8095/api/qc-classification", json=payload)
        logger.info(f"Spring Boot ì „ì†¡ ì™„ë£Œ: {insect_name} | ìƒíƒœ: {res.status_code}")
        
        # ì „í™” ë°œì‹ 
        await make_call(gh_idx, insect_name, confidence)
        
    except Exception as e:
        logger.error(f"Spring Boot ì „ì†¡ ì‹¤íŒ¨: {e}")

def draw_detections_on_hq_frame(detections: List[dict], lq_frame: np.ndarray, hq_frame: np.ndarray) -> np.ndarray:
    """
HQ í”„ë ˆì„ì— LQì—ì„œ íƒì§€ëœ ê²°ê³¼ë¥¼ ì‹œê°í™”
    """
    annotated_frame = hq_frame.copy()
    
    # í•´ìƒë„ ë¹„ìœ¨ ê³„ì‚° (LQ â†’ HQ ìŠ¤ì¼€ì¼ë§)
    lq_h, lq_w = lq_frame.shape[:2]
    hq_h, hq_w = hq_frame.shape[:2]
    
    scale_x = hq_w / lq_w
    scale_y = hq_h / lq_h
    
    # ê³¤ì¶© ì¢…ë¥˜ë³„ ìƒ‰ìƒ ì •ì˜
    colors = {
        "ê½ƒë…¸ë‘ì´ì±„ë²Œë ˆ": (0, 255, 255),  # ë…¸ë‘
        "ë‹´ë°°ê°€ë£¨ì´": (255, 255, 255),      # í•˜ì–€
        "ë¹„ë‹¨ë…¸ë¦°ì¬": (0, 255, 0),         # ì´ˆë¡
        "ì•Œë½ìˆ˜ì—¼ë…¸ë¦°ì¬": (255, 0, 0)     # ë¹¨ê°•
    }
    
    for detection in detections:
        # LQ bboxë¥¼ HQ ì¢Œí‘œê³„ë¡œ ë³€í™˜
        lq_bbox = detection["bbox"]  # [x_min, y_min, x_max, y_max]
        
        hq_x1 = int(lq_bbox[0] * scale_x)
        hq_y1 = int(lq_bbox[1] * scale_y)
        hq_x2 = int(lq_bbox[2] * scale_x)
        hq_y2 = int(lq_bbox[3] * scale_y)
        
        # ê²½ê³„ ê²€ì‚¬
        hq_x1 = max(0, min(hq_x1, hq_w-1))
        hq_y1 = max(0, min(hq_y1, hq_h-1))
        hq_x2 = max(hq_x1+1, min(hq_x2, hq_w))
        hq_y2 = max(hq_y1+1, min(hq_y2, hq_h))
        
        # ê³¤ì¶© ì¢…ë¥˜ì™€ ì‹ ë¢°ë„
        class_name = detection["class_name"]
        confidence = detection["confidence"]
        color = colors.get(class_name, (0, 255, 0))  # ê¸°ë³¸ ì´ˆë¡ìƒ‰
        
        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        cv2.rectangle(annotated_frame, (hq_x1, hq_y1), (hq_x2, hq_y2), color, 3)
        
        # ë ˆì´ë¸” ë°°ê²½ ê·¸ë¦¬ê¸°
        label = f"{class_name} {confidence:.2f}"
        (label_w, label_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)
        
        # ë ˆì´ë¸” ë°°ê²½ ì‚¬ê°í˜•
        cv2.rectangle(annotated_frame, (hq_x1, hq_y1 - label_h - 10), 
                     (hq_x1 + label_w + 10, hq_y1), color, -1)
        
        # ë ˆì´ë¸” í…ìŠ¤íŠ¸
        cv2.putText(annotated_frame, label, (hq_x1 + 5, hq_y1 - 5),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)
    
    return annotated_frame

async def create_annotated_video(annotated_frames: List[np.ndarray], request: VideoBufferRequest) -> str:
    """
ì‹œê°í™”ëœ í”„ë ˆì„ë“¤ë¡œ MP4 ë¹„ë””ì˜¤ ìƒì„±
    """
    try:
        # ë¹„ë””ì˜¤ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        video_dir = Path("data/processed_videos") / request.camera_id
        video_dir.mkdir(parents=True, exist_ok=True)
        
        # íŒŒì¼ëª… ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        video_filename = f"detection_{request.camera_id}_{timestamp}.mp4"
        video_path = video_dir / video_filename
        
        # ë¹„ë””ì˜¤ ë¼ì´í„° ì„¤ì • (OpenCV)
        if len(annotated_frames) == 0:
            logger.error("ë¹„ë””ì˜¤ ìƒì„±ì„ ìœ„í•œ í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        # ì²« ë²ˆì§¸ í”„ë ˆì„ì—ì„œ í•´ìƒë„ ì²˜ì˜
        valid_frame = None
        for frame in annotated_frames:
            if frame is not None:
                valid_frame = frame
                break
        
        if valid_frame is None:
            logger.error("ìœ íš¨í•œ í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        height, width = valid_frame.shape[:2]
        fps = 10  # ë¼ì¦ˆë² ë¦¬íŒŒì´ì˜ LQ FPSì™€ ë™ì¼
        
        # VideoWriter ì„¤ì •
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(str(video_path), fourcc, fps, (width, height))
        
        if not out.isOpened():
            logger.error("VideoWriter ì—´ê¸° ì‹¤íŒ¨")
            return None
        
        # í”„ë ˆì„ë“¤ì„ ë¹„ë””ì˜¤ë¡œ ì‘ì„±
        for i, frame in enumerate(annotated_frames):
            if frame is not None:
                # í•´ìƒë„ í†µì¼
                if frame.shape[:2] != (height, width):
                    frame = cv2.resize(frame, (width, height))
                out.write(frame)
            else:
                # ë¹ˆ í”„ë ˆì„ì¼ ê²½ìš° ì´ì „ í”„ë ˆì„ ì‚¬ìš©
                if i > 0 and annotated_frames[i-1] is not None:
                    prev_frame = annotated_frames[i-1]
                    if prev_frame.shape[:2] != (height, width):
                        prev_frame = cv2.resize(prev_frame, (width, height))
                    out.write(prev_frame)
        
        out.release()
        
        logger.info(f"âœ… ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {video_path}")
        return str(video_path)
        
    except Exception as e:
        logger.error(f"âŒ ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

async def send_video_to_spring_boot(video_path: str, request: VideoBufferRequest, detection_count: int):
    """
ìƒì„±ëœ ë¹„ë””ì˜¤ë¥¼ Spring Bootì„œë²„ë¡œ ì „ì†¡
    """
    import requests
    from pathlib import Path
    
    try:
        if not Path(video_path).exists():
            logger.error(f"ë¹„ë””ì˜¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {video_path}")
            return
        
        # Spring Boot ë¹„ë””ì˜¤ ì—…ë¡œë“œ API
        spring_boot_url = "http://localhost:8095/api/video/upload"
        
        # ë¹„ë””ì˜¤ íŒŒì¼ ë° ë©”íƒ€ë°ì´í„° ì¤€ë¹„
        with open(video_path, 'rb') as video_file:
            files = {
                'video': (Path(video_path).name, video_file, 'video/mp4')
            }
            
            data = {
                'camera_id': request.camera_id,
                'gh_idx': request.gh_idx,
                'detection_count': detection_count,
                'recording_start_time': request.recording_start_time,
                'frame_count': request.frame_count
            }
            
            response = requests.post(spring_boot_url, files=files, data=data, timeout=30)
            
            if response.status_code == 200:
                logger.info(f"âœ… Spring Boot ë¹„ë””ì˜¤ ì „ì†¡ ì„±ê³µ: {video_path}")
            else:
                logger.error(f"âŒ Spring Boot ë¹„ë””ì˜¤ ì „ì†¡ ì‹¤íŒ¨: {response.status_code}")
    
    except Exception as e:
        logger.error(f"âŒ Spring Boot ë¹„ë””ì˜¤ ì „ì†¡ ì˜¤ë¥˜: {e}")

async def make_call(gh_idx: int, insect_name: str, confidence: float):
    """ì „í™” ë°œì‹ """
    import requests
    
    try:
        ml_api_url = "http://localhost:8003/api/make-call"
        params = {
            "gh_idx": gh_idx,
            "insect_name": insect_name,
            "confidence": confidence
        }
        
        response = requests.post(ml_api_url, params=params, timeout=10)
        
        if response.status_code == 200:
            logger.info(f"ì „í™” ë°œì‹  ì„±ê³µ: {insect_name} (ì‹ ë¢°ë„: {confidence:.2f})")
        else:
            logger.error(f"ì „í™” ë°œì‹  ì‹¤íŒ¨: {response.status_code}")
            
    except Exception as e:
        logger.error(f"ì „í™” ë°œì‹  ì˜¤ë¥˜: {e}")