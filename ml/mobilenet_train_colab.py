# MobileNet V2 í•™ìŠµ ì½”ë“œ - Google Colabìš©
# 10ì¢… í•´ì¶© ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms, models
from PIL import Image
import os
import json
from tqdm import tqdm
import numpy as np

# GPU ì„¤ì •
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# í•´ì¶© í´ë˜ìŠ¤ ì •ì˜ (10ì¢…)
INSECT_CLASSES = {
    0: "ê½ƒë…¸ë‘ì´ì±„ë²Œë ˆ",     # í•´ì¶© O
    1: "ë‹´ë°°ê°€ë£¨ì´",         # í•´ì¶© O  
    2: "ë³µìˆ­ì•„í˜¹ì§„ë”§ë¬¼",      # í•´ì¶© O
    3: "ì©ë©ë‚˜ë¬´ë…¸ë¦°ì¬",      # í•´ì¶© O
    4: "ë¹„ë‹¨ë…¸ë¦°ì¬",         # í•´ì¶© X (ì¼ë°˜ê³¤ì¶©)
    5: "ë¨¹ë…¸ë¦°ì¬",           # í•´ì¶© X (ì¼ë°˜ê³¤ì¶©)
    6: "ë¬´ìë²Œ",            # í•´ì¶© X (ì¼ë°˜ê³¤ì¶©)
    7: "ë°°ì¶”ì¢€ë‚˜ë°©",         # í•´ì¶© X (ì¼ë°˜ê³¤ì¶©)
    8: "ë²¼ë£©ìë²Œë ˆ",         # í•´ì¶© X (ì¼ë°˜ê³¤ì¶©)
    9: "í°28ì ë°•ì´ë¬´ë‹¹ë²Œë ˆ"   # í•´ì¶© X (ì¼ë°˜ê³¤ì¶©)
}

class InsectDataset(Dataset):
    """í•´ì¶© ì´ë¯¸ì§€ ë°ì´í„°ì…‹"""
    def __init__(self, root_dir, transform=None, mode='train'):
        self.root_dir = root_dir
        self.transform = transform
        self.mode = mode
        self.samples = []
        
        # ë°ì´í„° ë¡œë“œ
        for class_idx, class_name in INSECT_CLASSES.items():
            class_dir = os.path.join(root_dir, mode, class_name)
            if os.path.exists(class_dir):
                for img_name in os.listdir(class_dir):
                    if img_name.endswith(('.jpg', '.png', '.jpeg')):
                        self.samples.append({
                            'path': os.path.join(class_dir, img_name),
                            'label': class_idx
                        })
        
        print(f"{mode} ë°ì´í„°ì…‹: {len(self.samples)}ê°œ ìƒ˜í”Œ ë¡œë“œ")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        sample = self.samples[idx]
        image = Image.open(sample['path']).convert('RGB')
        
        if self.transform:
            image = self.transform(image)
        
        return image, sample['label']

class MobileNetInsectClassifier(nn.Module):
    """MobileNet V2 ê¸°ë°˜ í•´ì¶© ë¶„ë¥˜ ëª¨ë¸"""
    def __init__(self, num_classes=10, pretrained=True):
        super(MobileNetInsectClassifier, self).__init__()
        
        # MobileNet V2 ë°±ë³¸
        self.mobilenet = models.mobilenet_v2(pretrained=pretrained)
        
        # ë¶„ë¥˜ í—¤ë“œ êµì²´
        in_features = self.mobilenet.classifier[1].in_features
        self.mobilenet.classifier = nn.Sequential(
            nn.Dropout(0.2),
            nn.Linear(in_features, 256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, num_classes)
        )
        
    def forward(self, x):
        return self.mobilenet(x)

def train_model(model, train_loader, val_loader, epochs=30, lr=0.001):
    """ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜"""
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)
    
    best_val_acc = 0
    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}
    
    for epoch in range(epochs):
        # Training
        model.train()
        train_loss = 0
        train_correct = 0
        train_total = 0
        
        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Train]')
        for images, labels in pbar:
            images, labels = images.to(device), labels.to(device)
            
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            _, predicted = outputs.max(1)
            train_total += labels.size(0)
            train_correct += predicted.eq(labels).sum().item()
            
            pbar.set_postfix({'loss': f'{loss.item():.4f}', 
                             'acc': f'{100.*train_correct/train_total:.2f}%'})
        
        # Validation
        model.eval()
        val_loss = 0
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for images, labels in tqdm(val_loader, desc=f'Epoch {epoch+1}/{epochs} [Val]'):
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)
                
                val_loss += loss.item()
                _, predicted = outputs.max(1)
                val_total += labels.size(0)
                val_correct += predicted.eq(labels).sum().item()
        
        # ì—í­ ê²°ê³¼
        train_acc = 100. * train_correct / train_total
        val_acc = 100. * val_correct / val_total
        avg_train_loss = train_loss / len(train_loader)
        avg_val_loss = val_loss / len(val_loader)
        
        print(f'\nEpoch {epoch+1}: Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%')
        print(f'         Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%')
        
        # ê¸°ë¡ ì €ì¥
        history['train_loss'].append(avg_train_loss)
        history['train_acc'].append(train_acc)
        history['val_loss'].append(avg_val_loss)
        history['val_acc'].append(val_acc)
        
        # í•™ìŠµë¥  ì¡°ì •
        scheduler.step(avg_val_loss)
        
        # ìµœê³  ëª¨ë¸ ì €ì¥
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_acc': val_acc,
                'class_names': INSECT_CLASSES
            }, 'best_mobilenet_insect.pt')
            print(f'âœ… ìµœê³  ëª¨ë¸ ì €ì¥ (Val Acc: {val_acc:.2f}%)')
    
    return history

def export_to_onnx(model, dummy_input, filename='mobilenet_insect.onnx'):
    """ONNX í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸° (ë¼ì¦ˆë² ë¦¬íŒŒì´ìš©)"""
    model.eval()
    torch.onnx.export(
        model,
        dummy_input,
        filename,
        export_params=True,
        opset_version=11,
        do_constant_folding=True,
        input_names=['input'],
        output_names=['output'],
        dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}
    )
    print(f"âœ… ONNX ëª¨ë¸ ì €ì¥: {filename}")

def test_model(model, test_loader):
    """ìµœì¢… í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    model.eval()
    correct = 0
    total = 0
    class_correct = list(0. for i in range(10))
    class_total = list(0. for i in range(10))
    
    with torch.no_grad():
        for images, labels in tqdm(test_loader, desc='Testing'):
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            
            # í´ë˜ìŠ¤ë³„ ì •í™•ë„
            c = (predicted == labels).squeeze()
            for i in range(labels.size(0)):
                label = labels[i]
                class_correct[label] += c[i].item()
                class_total[label] += 1
    
    # ì „ì²´ ì •í™•ë„
    print(f'\nğŸ“Š Test Accuracy: {100 * correct/total:.2f}%')
    
    # í´ë˜ìŠ¤ë³„ ì •í™•ë„
    print('\ní´ë˜ìŠ¤ë³„ ì •í™•ë„:')
    for i in range(10):
        if class_total[i] > 0:
            acc = 100 * class_correct[i]/class_total[i]
            print(f'{INSECT_CLASSES[i]}: {acc:.2f}%')
    
    return 100 * correct/total    

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ë°ì´í„° ë³€í™˜ ì •ì˜
    transform_train = transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(15),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    transform_val = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    # ë°ì´í„°ì…‹ ê²½ë¡œ (Colabì—ì„œ ìˆ˜ì • í•„ìš”)
    data_root = '/content/drive/MyDrive/insect_dataset'
    
    # ë°ì´í„°ì…‹ ìƒì„±
    train_dataset = InsectDataset(data_root, transform=transform_train, mode='train')
    val_dataset = InsectDataset(data_root, transform=transform_val, mode='val')
    
    # Test ë°ì´í„°ì…‹ ì¶”ê°€ âœ¨
    test_dataset = InsectDataset(data_root, transform=transform_val, mode='test')
    
    # ë°ì´í„°ë¡œë”
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)
    
    # Test ë°ì´í„°ë¡œë” ì¶”ê°€ âœ¨
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)
    
    # ëª¨ë¸ ìƒì„±
    model = MobileNetInsectClassifier(num_classes=10, pretrained=True)
    model = model.to(device)
    
    # í•™ìŠµ
    print("\nğŸš€ í•™ìŠµ ì‹œì‘...")
    history = train_model(model, train_loader, val_loader, epochs=30)
    
    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ âœ¨
    print("\nğŸ“‚ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ ì¤‘...")
    checkpoint = torch.load('best_mobilenet_insect.pt')
    model.load_state_dict(checkpoint['model_state_dict'])
    print(f"âœ… Epoch {checkpoint['epoch']+1}ì˜ ëª¨ë¸ ë¡œë“œ (Val Acc: {checkpoint['val_acc']:.2f}%)")
    
    # Test ë°ì´í„°ì…‹ìœ¼ë¡œ ìµœì¢… í‰ê°€ âœ¨
    print("\nğŸ” Test ë°ì´í„°ì…‹ìœ¼ë¡œ ìµœì¢… í‰ê°€ ì¤‘...")
    test_accuracy = test_model(model, test_loader)
    
    # ìµœì¢… ëª¨ë¸ ì €ì¥ (best ëª¨ë¸ ê¸°ì¤€)
    torch.save(model.state_dict(), 'final_mobilenet_insect.pt')
    
    # ONNX ë‚´ë³´ë‚´ê¸° (best ëª¨ë¸ ê¸°ì¤€)
    dummy_input = torch.randn(1, 3, 224, 224).to(device)
    export_to_onnx(model, dummy_input)
    
    # í•™ìŠµ ê¸°ë¡ ì €ì¥ (test ê²°ê³¼ í¬í•¨) âœ¨
    history['test_acc'] = test_accuracy
    with open('training_history.json', 'w') as f:
        json.dump(history, f)
    
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥ âœ¨
    print("\n" + "="*50)
    print("âœ… í•™ìŠµ ë° í‰ê°€ ì™„ë£Œ!")
    print("="*50)
    print(f"ğŸ“Š ìµœê³  Validation ì •í™•ë„: {max(history['val_acc']):.2f}%")
    print(f"ğŸ“Š ìµœì¢… Test ì •í™•ë„: {test_accuracy:.2f}%")
    print("="*50)
    
    # ê³¼ì í•© í™•ì¸ âœ¨
    if max(history['val_acc']) - test_accuracy > 5:
        print("âš ï¸ ì£¼ì˜: Validationê³¼ Test ì •í™•ë„ ì°¨ì´ê°€ 5% ì´ìƒì…ë‹ˆë‹¤.")
        print("   ê³¼ì í•©(Overfitting) ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.")
    else:
        print("âœ… ëª¨ë¸ì´ ì˜ ì¼ë°˜í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    main()

# Colab ì‚¬ìš©ë²•:
# 1. Google Drive ë§ˆìš´íŠ¸: from google.colab import drive; drive.mount('/content/drive')
# 2. ë°ì´í„°ì…‹ ì—…ë¡œë“œ: /content/drive/MyDrive/insect_dataset/ ê²½ë¡œì— ì—…ë¡œë“œ
# 3. ì‹¤í–‰: !python mobilenet_train_colab.py
# 4. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: best_mobilenet_insect.pt, mobilenet_insect.onnx