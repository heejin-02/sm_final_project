"""
Open Set Recognition í…ŒìŠ¤íŠ¸ ë° ë””ë²„ê¹…
ì„ê³„ê°’ ë¬¸ì œ í•´ê²° ë²„ì „
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from torchvision import models, transforms
import cv2
import os
import logging
from PIL import Image
from sklearn.covariance import EmpiricalCovariance

# ========================
# ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ (í•„ìˆ˜!)
# ========================

class CalibratedOpenSetModel(nn.Module):
    """train_prototypes.pyì™€ ë™ì¼í•œ ëª¨ë¸ êµ¬ì¡°"""
    def __init__(self, num_classes=4, feature_dim=512, initial_temperature=1.5):
        super().__init__()
        
        resnet = models.resnet101(weights=None)
        self.features = nn.Sequential(*list(resnet.children())[:-1])
        
        self.encoder = nn.Sequential(
            nn.Linear(2048, 1024),
            nn.BatchNorm1d(1024),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(1024, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, feature_dim)
        )
        
        self.main_classifier = nn.Linear(feature_dim, num_classes)
        self.auxiliary_classifier = nn.Linear(feature_dim, num_classes)
        
        self.decoder = nn.Sequential(
            nn.Linear(feature_dim, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Linear(512, 1024),
            nn.BatchNorm1d(1024),
            nn.ReLU(),
            nn.Linear(1024, 2048)
        )
        
        self.prototype_layer = nn.Linear(feature_dim, num_classes, bias=False)
        self.temperature = nn.Parameter(torch.ones(1) * initial_temperature)
        self.class_thresholds = nn.Parameter(torch.ones(num_classes) * 0.5)
    
    def forward(self, x, return_all=False):
        cnn_features = self.features(x)
        cnn_features = cnn_features.view(cnn_features.size(0), -1)
        
        features = self.encoder(cnn_features)
        logits = self.main_classifier(features)
        aux_logits = self.auxiliary_classifier(features)
        
        prototypes = F.normalize(self.prototype_layer.weight, dim=1)
        normalized_features = F.normalize(features, dim=1)
        distances = torch.cdist(normalized_features.unsqueeze(1),
                               prototypes.unsqueeze(0), p=2).squeeze(1)
        
        if return_all:
            reconstructed = self.decoder(features)
            reconstruction_error = F.mse_loss(reconstructed, cnn_features, reduction='none')
            reconstruction_error = reconstruction_error.mean(dim=1)
            
            return {
                'logits': logits,
                'aux_logits': aux_logits,
                'features': features,
                'reconstruction_error': reconstruction_error,
                'distances': distances,
                'cnn_features': cnn_features
            }
        
        return logits, features

# ========================
# ê°œì„ ëœ ì¸ì‹ê¸°
# ========================

class ImprovedOpenSetRecognizer:
    def __init__(self, model_path='improved_pest_detection_model.pth', device='cpu'):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        self.logger = logging.getLogger(__name__)
        
        self.known_insects = {
            0: "ê½ƒë…¸ë‘ì´ì±„ë²Œë ˆ",
            1: "ë‹´ë°°ê°€ë£¨ì´",
            2: "ë³µìˆ­ì•„í˜¹ì§„ë”§ë¬¼",
            3: "ì©ë©ë‚˜ë¬´ë…¸ë¦°ì¬"
        }
        
        self._load_model(model_path)
        
        self.transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        self.logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
        self.logger.info(f"ğŸ“Š Device: {self.device}")
    
    def _load_model(self, model_path):
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        
        checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
        
        # ëª¨ë¸ ì´ˆê¸°í™” (temperature í¬í•¨)
        config = checkpoint.get('config', {})
        self.model = CalibratedOpenSetModel(
            num_classes=config.get('num_classes', 4),
            feature_dim=config.get('feature_dim', 512),
            initial_temperature=config.get('temperature', 1.5)
        )
        
        # state_dict ë¡œë“œ
        state_dict = checkpoint['model_state']
        
        self.model.load_state_dict(state_dict)
        self.model.to(self.device)
        self.model.eval()
        
        # ì„ê³„ê°’ ë° í†µê³„ ë¡œë“œ (ìˆìœ¼ë©´)
        if 'thresholds' in checkpoint:
            self.original_thresholds = checkpoint['thresholds'].copy()
            self.thresholds = checkpoint['thresholds']
            self.logger.info("âœ… ì €ì¥ëœ ì„ê³„ê°’ ë¡œë“œ")
        else:
            # ê¸°ë³¸ ì„ê³„ê°’ ì„¤ì •
            self.logger.warning("âš ï¸ ì €ì¥ëœ ì„ê³„ê°’ ì—†ìŒ - ê¸°ë³¸ê°’ ì‚¬ìš©")
            self.original_thresholds = {
                'max_prob': 0.5,
                'entropy': 0.2,
                'min_distance': 1.336,
                'mahal_distance': 57.75,
                'recon_error': 0.064,
                'known_acc': 0.8,
                'unknown_reject': 0.7
            }
            self.thresholds = self.original_thresholds.copy()
        
        if 'class_statistics' in checkpoint:
            self.class_statistics = checkpoint['class_statistics']
            self.logger.info("âœ… í´ë˜ìŠ¤ í†µê³„ ë¡œë“œ")
        else:
            self.logger.warning("âš ï¸ í´ë˜ìŠ¤ í†µê³„ ì—†ìŒ - ë¹ˆ ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©")
            self.class_statistics = {}
        
        # ì„ê³„ê°’ ì¡°ì • (í•µì‹¬!)
        self._adjust_thresholds()
    
    def _adjust_thresholds(self):
        """ì„ê³„ê°’ì„ ì‹¤ìš©ì ì¸ ê°’ìœ¼ë¡œ ì¡°ì •"""
        # ì‹¤ì œ ì €ì¥ëœ ì„ê³„ê°’ (Colabì—ì„œ í™•ì¸):
        # max_prob: 0.5
        # entropy: 0.2  
        # min_distance: 1.336
        # mahal_distance: 57.75
        # recon_error: 0.064
        
        # min_distanceë¥¼ ë” ê´€ëŒ€í•˜ê²Œ ì¡°ì • (1.336 -> 2.0)
        self.thresholds['min_distance'] = 2.0
        
        # max_probë¥¼ ë” ì—„ê²©í•˜ê²Œ (0.5 -> 0.7)
        self.thresholds['max_prob'] = 0.7
        
        # entropyëŠ” ì ì ˆí•´ ë³´ì„ (0.2 ìœ ì§€í•˜ë˜ ì‚´ì§ ì™„í™”)
        self.thresholds['entropy'] = 0.3
        
        # mahal_distance ì¡°ì • (57.75 -> 80)
        self.thresholds['mahal_distance'] = 80.0
        
        # recon_error ì¡°ì • (0.064 -> 0.1)
        self.thresholds['recon_error'] = 0.1
        
        self.logger.info("ğŸ“ˆ ì¡°ì •ëœ ì„ê³„ê°’:")
        for key, value in self.thresholds.items():
            original = self.original_thresholds.get(key, 'N/A')
            if isinstance(original, float):
                self.logger.info(f"   - {key}: {original:.3f} -> {value:.3f}")
            else:
                self.logger.info(f"   - {key}: {original} -> {value:.3f}")
    
    def calculate_mahalanobis_distance(self, features):
        min_mahal = float('inf')
        best_class = -1
        
        for class_id, stats in self.class_statistics.items():
            if stats is not None:
                diff = features - stats['mean']
                if 'precision' in stats and stats['precision'] is not None:
                    try:
                        mahal = np.sqrt(np.abs(diff @ stats['precision'] @ diff))
                    except:
                        mahal = np.linalg.norm(diff)
                else:
                    mahal = np.linalg.norm(diff)
                
                if mahal < min_mahal:
                    min_mahal = mahal
                    best_class = class_id
        
        return min_mahal, best_class
    
    def predict_single(self, image, debug=False):
        if isinstance(image, np.ndarray):
            if len(image.shape) == 2:
                image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
            elif image.shape[2] == 4:
                image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)
            elif image.shape[2] == 3:
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            image = Image.fromarray(image)
        
        image_tensor = self.transform(image).unsqueeze(0).to(self.device)
        
        with torch.no_grad():
            outputs = self.model(image_tensor, return_all=True)
            
            logits = outputs['logits']
            features = outputs['features'].cpu().numpy()[0]
            recon_error = outputs['reconstruction_error'].cpu().item()
            distances = outputs['distances']
            
            probs = F.softmax(logits, dim=1)
            max_prob, predicted_class = probs.max(dim=1)
            max_prob = max_prob.item()
            predicted_class = predicted_class.item()
            
            entropy = -torch.sum(probs * torch.log(probs + 1e-8), dim=1).item()
            min_distance = distances.min(dim=1)[0].item()
            mahal_distance, mahal_class = self.calculate_mahalanobis_distance(features)
            
            # ë””ë²„ê¹… ëª¨ë“œ
            if debug:
                print("\n=== ì„ê³„ê°’ ì²´í¬ (ë””ë²„ê¹…) ===")
                print(f"Predicted class: {predicted_class} ({self.known_insects[predicted_class]})")
                print(f"Max Prob: {max_prob:.4f} >= {self.thresholds['max_prob']:.4f}? "
                      f"{'âœ…' if max_prob >= self.thresholds['max_prob'] else 'âŒ'}")
                print(f"Entropy: {entropy:.4f} <= {self.thresholds['entropy']:.4f}? "
                      f"{'âœ…' if entropy <= self.thresholds['entropy'] else 'âŒ'}")
                print(f"Min Distance: {min_distance:.4f} <= {self.thresholds['min_distance']:.4f}? "
                      f"{'âœ…' if min_distance <= self.thresholds['min_distance'] else 'âŒ'}")
                print(f"Mahal Distance: {mahal_distance:.4f} <= {self.thresholds.get('mahal_distance', 100):.4f}? "
                      f"{'âœ…' if mahal_distance <= self.thresholds.get('mahal_distance', 100) else 'âŒ'}")
                print(f"Recon Error: {recon_error:.4f} <= {self.thresholds.get('recon_error', 0.1):.4f}? "
                      f"{'âœ…' if recon_error <= self.thresholds.get('recon_error', 0.1) else 'âŒ'}")
            
            # Unknown íŒë‹¨
            is_unknown = False
            rejection_reasons = []
            
            if max_prob < self.thresholds['max_prob']:
                is_unknown = True
                rejection_reasons.append(f"ë‚®ì€ ì‹ ë¢°ë„: {max_prob:.3f}")
            
            if entropy > self.thresholds['entropy']:
                is_unknown = True
                rejection_reasons.append(f"ë†’ì€ ì—”íŠ¸ë¡œí”¼: {entropy:.3f}")
            
            if min_distance > self.thresholds['min_distance']:
                is_unknown = True
                rejection_reasons.append(f"í”„ë¡œí† íƒ€ì…ê³¼ ê±°ë¦¬ ë©€ìŒ: {min_distance:.3f}")
            
            if mahal_distance > self.thresholds.get('mahal_distance', 100):
                is_unknown = True
                rejection_reasons.append(f"ë†’ì€ ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬: {mahal_distance:.3f}")
            
            if recon_error > self.thresholds.get('recon_error', 0.1):
                is_unknown = True
                rejection_reasons.append(f"ë†’ì€ ì¬êµ¬ì„± ì˜¤ë¥˜: {recon_error:.6f}")
            
            if is_unknown:
                return {
                    'class_id': -1,
                    'class_name': 'ë¯¸í™•ì¸ í•´ì¶©',
                    'confidence': max_prob,
                    'is_known': False,
                    'rejection_reasons': rejection_reasons,
                    'details': {
                        'max_prob': max_prob,
                        'entropy': entropy,
                        'min_distance': min_distance,
                        'mahal_distance': mahal_distance,
                        'recon_error': recon_error
                    }
                }
            else:
                return {
                    'class_id': predicted_class,
                    'class_name': self.known_insects[predicted_class],
                    'confidence': max_prob,
                    'is_known': True,
                    'rejection_reasons': [],
                    'details': {
                        'max_prob': max_prob,
                        'entropy': entropy,
                        'min_distance': min_distance,
                        'mahal_distance': mahal_distance,
                        'recon_error': recon_error
                    }
                }

# ========================
# ë©”ì¸ í…ŒìŠ¤íŠ¸ ì½”ë“œ
# ========================

if __name__ == "__main__":
    import logging
    logging.basicConfig(level=logging.INFO, 
                       format='%(asctime)s - %(levelname)s - %(message)s')
    
    # 1. ëª¨ë¸ ë¡œë“œ
    MODEL_PATH = 'improved_pest_detection_model.pth'
    
    recognizer = ImprovedOpenSetRecognizer(
        model_path=MODEL_PATH,
        device='cuda' if torch.cuda.is_available() else 'cpu'
    )
    
    # 2. í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ëª©ë¡
    test_images = [
        ('test_unknown.jpg', 'ì™„ì „ ì²˜ìŒ ë³´ëŠ” ì´ë¯¸ì§€'),
        ('test_image.jpg', 'Test ë°ì´í„°ì…‹ ì´ë¯¸ì§€'),
        ('train_image.jpg', 'Train ë°ì´í„°ì…‹ ì´ë¯¸ì§€'),
    ]
    
    # 3. ê° ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸
    for image_path, description in test_images:
        if os.path.exists(image_path):
            print(f"\n{'='*60}")
            print(f"í…ŒìŠ¤íŠ¸: {description} ({image_path})")
            print('='*60)
            
            image = cv2.imread(image_path)
            
            # ë””ë²„ê·¸ ëª¨ë“œë¡œ ì˜ˆì¸¡
            result = recognizer.predict_single(image, debug=True)
            
            print(f"\n========== ì˜ˆì¸¡ ê²°ê³¼ ==========")
            print(f"í´ë˜ìŠ¤: {result['class_name']}")
            print(f"ì‹ ë¢°ë„: {result['confidence']:.3f}")
            print(f"Known ì—¬ë¶€: {result['is_known']}")
            
            if not result['is_known']:
                print(f"ê±°ë¶€ ì´ìœ : {', '.join(result['rejection_reasons'])}")
            
            print(f"\nì„¸ë¶€ ì ìˆ˜:")
            for key, value in result['details'].items():
                print(f"  - {key}: {value:.4f}")
        else:
            print(f"\nâš ï¸ íŒŒì¼ ì—†ìŒ: {image_path}")