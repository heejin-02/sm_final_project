"""
Open Set Recognition ÌÖåÏä§Ìä∏ Î∞è ÎîîÎ≤ÑÍπÖ
ÏûÑÍ≥ÑÍ∞í Î¨∏Ï†ú Ìï¥Í≤∞ Î≤ÑÏ†Ñ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from torchvision import models, transforms
import cv2
import os
import logging
from PIL import Image
from sklearn.covariance import EmpiricalCovariance

# ========================
# Î™®Îç∏ ÌÅ¥ÎûòÏä§ Ï†ïÏùò (ÌïÑÏàò!)
# ========================

class CalibratedOpenSetModel(nn.Module):
    """train_prototypes.pyÏôÄ ÎèôÏùºÌïú Î™®Îç∏ Íµ¨Ï°∞"""
    def __init__(self, num_classes=4, feature_dim=512, initial_temperature=1.5):
        super().__init__()
        
        resnet = models.resnet101(weights=None)
        self.features = nn.Sequential(*list(resnet.children())[:-1])
        
        self.encoder = nn.Sequential(
            nn.Linear(2048, 1024),
            nn.BatchNorm1d(1024),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(1024, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, feature_dim)
        )
        
        self.main_classifier = nn.Linear(feature_dim, num_classes)
        self.auxiliary_classifier = nn.Linear(feature_dim, num_classes)
        
        self.decoder = nn.Sequential(
            nn.Linear(feature_dim, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Linear(512, 1024),
            nn.BatchNorm1d(1024),
            nn.ReLU(),
            nn.Linear(1024, 2048)
        )
        
        self.prototype_layer = nn.Linear(feature_dim, num_classes, bias=False)
        self.temperature = nn.Parameter(torch.ones(1) * initial_temperature)
        self.class_thresholds = nn.Parameter(torch.ones(num_classes) * 0.5)
    
    def forward(self, x, return_all=False):
        cnn_features = self.features(x)
        cnn_features = cnn_features.view(cnn_features.size(0), -1)
        
        features = self.encoder(cnn_features)
        logits = self.main_classifier(features)
        aux_logits = self.auxiliary_classifier(features)
        
        prototypes = F.normalize(self.prototype_layer.weight, dim=1)
        normalized_features = F.normalize(features, dim=1)
        distances = torch.cdist(normalized_features.unsqueeze(1),
                               prototypes.unsqueeze(0), p=2).squeeze(1)
        
        if return_all:
            reconstructed = self.decoder(features)
            reconstruction_error = F.mse_loss(reconstructed, cnn_features, reduction='none')
            reconstruction_error = reconstruction_error.mean(dim=1)
            
            return {
                'logits': logits,
                'aux_logits': aux_logits,
                'features': features,
                'reconstruction_error': reconstruction_error,
                'distances': distances,
                'cnn_features': cnn_features
            }
        
        return logits, features

# ========================
# Í∞úÏÑ†Îêú Ïù∏ÏãùÍ∏∞
# ========================

class ImprovedOpenSetRecognizer:
    def __init__(self, model_path='improved_pest_detection_model.pth', device='cpu'):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        self.logger = logging.getLogger(__name__)
        
        self.known_insects = {
            0: "ÍΩÉÎÖ∏ÎûëÏ¥ùÏ±ÑÎ≤åÎ†à",
            1: "Îã¥Î∞∞Í∞ÄÎ£®Ïù¥",
            2: "Î≥µÏà≠ÏïÑÌòπÏßÑÎîßÎ¨º",
            3: "Ïç©Îç©ÎÇòÎ¨¥ÎÖ∏Î¶∞Ïû¨"
        }
        
        self._load_model(model_path)
        
        self.transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        self.logger.info(f"‚úÖ Î™®Îç∏ Î°úÎìú ÏôÑÎ£å: {model_path}")
        self.logger.info(f"üìä Device: {self.device}")
    
    def _load_model(self, model_path):
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Î™®Îç∏ ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {model_path}")
        
        checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
        
        # Î™®Îç∏ Ï¥àÍ∏∞Ìôî (temperature Ìè¨Ìï®)
        config = checkpoint.get('config', {})
        self.model = CalibratedOpenSetModel(
            num_classes=config.get('num_classes', 4),
            feature_dim=config.get('feature_dim', 512),
            initial_temperature=config.get('temperature', 1.5)
        )
        
        # state_dict Î°úÎìú
        state_dict = checkpoint['model_state']
        
        self.model.load_state_dict(state_dict)
        self.model.to(self.device)
        self.model.eval()
        
        # ÏûÑÍ≥ÑÍ∞í Î∞è ÌÜµÍ≥Ñ Î°úÎìú (ÏûàÏúºÎ©¥)
        if 'thresholds' in checkpoint:
            self.original_thresholds = checkpoint['thresholds'].copy()
            self.thresholds = checkpoint['thresholds']
            self.logger.info("‚úÖ Ï†ÄÏû•Îêú ÏûÑÍ≥ÑÍ∞í Î°úÎìú")
        else:
            # Í∏∞Î≥∏ ÏûÑÍ≥ÑÍ∞í ÏÑ§Ï†ï
            self.logger.warning("‚ö†Ô∏è Ï†ÄÏû•Îêú ÏûÑÍ≥ÑÍ∞í ÏóÜÏùå - Í∏∞Î≥∏Í∞í ÏÇ¨Ïö©")
            self.original_thresholds = {
                'max_prob': 0.5,
                'entropy': 0.2,
                'min_distance': 1.336,
                'mahal_distance': 57.75,
                'recon_error': 0.064,
                'known_acc': 0.8,
                'unknown_reject': 0.7
            }
            self.thresholds = self.original_thresholds.copy()
        
        if 'class_statistics' in checkpoint:
            self.class_statistics = checkpoint['class_statistics']
            self.logger.info("‚úÖ ÌÅ¥ÎûòÏä§ ÌÜµÍ≥Ñ Î°úÎìú")
        else:
            self.logger.warning("‚ö†Ô∏è ÌÅ¥ÎûòÏä§ ÌÜµÍ≥Ñ ÏóÜÏùå - Îπà ÎîïÏÖîÎÑàÎ¶¨ ÏÇ¨Ïö©")
            self.class_statistics = {}
        
        # ÏûÑÍ≥ÑÍ∞í Ï°∞Ï†ï (ÌïµÏã¨!)
        self._adjust_thresholds()
    
    def _adjust_thresholds(self):
        """ÏûÑÍ≥ÑÍ∞íÏùÑ Ïã§Ïö©Ï†ÅÏù∏ Í∞íÏúºÎ°ú Ï°∞Ï†ï"""
        # Ïã§Ï†ú Ï†ÄÏû•Îêú ÏûÑÍ≥ÑÍ∞í (ColabÏóêÏÑú ÌôïÏù∏):
        # max_prob: 0.5
        # entropy: 0.2  
        # min_distance: 1.336
        # mahal_distance: 57.75
        # recon_error: 0.064
        
        # min_distanceÎ•º Îçî Í¥ÄÎåÄÌïòÍ≤å Ï°∞Ï†ï (1.336 -> 2.0)
        self.thresholds['min_distance'] = 2.0
        
        # max_probÎ•º Îçî ÏóÑÍ≤©ÌïòÍ≤å (0.5 -> 0.7)
        self.thresholds['max_prob'] = 0.7
        
        # entropyÎäî Ï†ÅÏ†àÌï¥ Î≥¥ÏûÑ (0.2 Ïú†ÏßÄÌïòÎêò ÏÇ¥Ïßù ÏôÑÌôî)
        self.thresholds['entropy'] = 0.3
        
        # mahal_distance Ï°∞Ï†ï (57.75 -> 80)
        self.thresholds['mahal_distance'] = 80.0
        
        # recon_error Ï°∞Ï†ï (0.064 -> 0.1)
        self.thresholds['recon_error'] = 0.1
        
        self.logger.info("üìà Ï°∞Ï†ïÎêú ÏûÑÍ≥ÑÍ∞í:")
        for key, value in self.thresholds.items():
            original = self.original_thresholds.get(key, 'N/A')
            if isinstance(original, float):
                self.logger.info(f"   - {key}: {original:.3f} -> {value:.3f}")
            else:
                self.logger.info(f"   - {key}: {original} -> {value:.3f}")
    
    def calculate_mahalanobis_distance(self, features):
        min_mahal = float('inf')
        best_class = -1
        
        for class_id, stats in self.class_statistics.items():
            if stats is not None:
                diff = features - stats['mean']
                if 'precision' in stats and stats['precision'] is not None:
                    try:
                        mahal = np.sqrt(np.abs(diff @ stats['precision'] @ diff))
                    except:
                        mahal = np.linalg.norm(diff)
                else:
                    mahal = np.linalg.norm(diff)
                
                if mahal < min_mahal:
                    min_mahal = mahal
                    best_class = class_id
        
        return min_mahal, best_class
    
    def predict_single(self, image, debug=False):
        if isinstance(image, np.ndarray):
            if len(image.shape) == 2:
                image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
            elif image.shape[2] == 4:
                image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)
            elif image.shape[2] == 3:
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            image = Image.fromarray(image)
        
        image_tensor = self.transform(image).unsqueeze(0).to(self.device)
        
        with torch.no_grad():
            outputs = self.model(image_tensor, return_all=True)
            
            logits = outputs['logits']
            features = outputs['features'].cpu().numpy()[0]
            recon_error = outputs['reconstruction_error'].cpu().item()
            distances = outputs['distances']
            
            probs = F.softmax(logits, dim=1)
            max_prob, predicted_class = probs.max(dim=1)
            max_prob = max_prob.item()
            predicted_class = predicted_class.item()
            
            entropy = -torch.sum(probs * torch.log(probs + 1e-8), dim=1).item()
            min_distance = distances.min(dim=1)[0].item()
            mahal_distance, mahal_class = self.calculate_mahalanobis_distance(features)
            
            # ÎîîÎ≤ÑÍπÖ Î™®Îìú
            if debug:
                print("\n=== ÏûÑÍ≥ÑÍ∞í Ï≤¥ÌÅ¨ (ÎîîÎ≤ÑÍπÖ) ===")
                print(f"Predicted class: {predicted_class} ({self.known_insects[predicted_class]})")
                print(f"Max Prob: {max_prob:.4f} >= {self.thresholds['max_prob']:.4f}? "
                      f"{'‚úÖ' if max_prob >= self.thresholds['max_prob'] else '‚ùå'}")
                print(f"Entropy: {entropy:.4f} <= {self.thresholds['entropy']:.4f}? "
                      f"{'‚úÖ' if entropy <= self.thresholds['entropy'] else '‚ùå'}")
                print(f"Min Distance: {min_distance:.4f} <= {self.thresholds['min_distance']:.4f}? "
                      f"{'‚úÖ' if min_distance <= self.thresholds['min_distance'] else '‚ùå'}")
                print(f"Mahal Distance: {mahal_distance:.4f} <= {self.thresholds.get('mahal_distance', 100):.4f}? "
                      f"{'‚úÖ' if mahal_distance <= self.thresholds.get('mahal_distance', 100) else '‚ùå'}")
                print(f"Recon Error: {recon_error:.4f} <= {self.thresholds.get('recon_error', 0.1):.4f}? "
                      f"{'‚úÖ' if recon_error <= self.thresholds.get('recon_error', 0.1) else '‚ùå'}")
            
            # Unknown ÌåêÎã®
            is_unknown = False
            rejection_reasons = []
            
            if max_prob < self.thresholds['max_prob']:
                is_unknown = True
                rejection_reasons.append(f"ÎÇÆÏùÄ Ïã†Î¢∞ÎèÑ: {max_prob:.3f}")
            
            if entropy > self.thresholds['entropy']:
                is_unknown = True
                rejection_reasons.append(f"ÎÜíÏùÄ ÏóîÌä∏Î°úÌîº: {entropy:.3f}")
            
            if min_distance > self.thresholds['min_distance']:
                is_unknown = True
                rejection_reasons.append(f"ÌîÑÎ°úÌÜ†ÌÉÄÏûÖÍ≥º Í±∞Î¶¨ Î©ÄÏùå: {min_distance:.3f}")
            
            if mahal_distance > self.thresholds.get('mahal_distance', 100):
                is_unknown = True
                rejection_reasons.append(f"ÎÜíÏùÄ ÎßàÌï†ÎùºÎÖ∏ÎπÑÏä§ Í±∞Î¶¨: {mahal_distance:.3f}")
            
            if recon_error > self.thresholds.get('recon_error', 0.1):
                is_unknown = True
                rejection_reasons.append(f"ÎÜíÏùÄ Ïû¨Íµ¨ÏÑ± Ïò§Î•ò: {recon_error:.6f}")
            
            if is_unknown:
                return {
                    'class_id': -1,
                    'class_name': 'ÎØ∏ÌôïÏù∏ Ìï¥Ï∂©',
                    'confidence': max_prob,
                    'is_known': False,
                    'rejection_reasons': rejection_reasons,
                    'details': {
                        'max_prob': max_prob,
                        'entropy': entropy,
                        'min_distance': min_distance,
                        'mahal_distance': mahal_distance,
                        'recon_error': recon_error
                    }
                }
            else:
                return {
                    'class_id': predicted_class,
                    'class_name': self.known_insects[predicted_class],
                    'confidence': max_prob,
                    'is_known': True,
                    'rejection_reasons': [],
                    'details': {
                        'max_prob': max_prob,
                        'entropy': entropy,
                        'min_distance': min_distance,
                        'mahal_distance': mahal_distance,
                        'recon_error': recon_error
                    }
                }

# ========================
# Î©îÏù∏ ÌÖåÏä§Ìä∏ ÏΩîÎìú
# ========================

if __name__ == "__main__":
    import logging
    logging.basicConfig(level=logging.INFO, 
                       format='%(asctime)s - %(levelname)s - %(message)s')
    
    # 1. Î™®Îç∏ Î°úÎìú
    MODEL_PATH = 'improved_pest_detection_model.pth'
    
    recognizer = ImprovedOpenSetRecognizer(
        model_path=MODEL_PATH,
        device='cuda' if torch.cuda.is_available() else 'cpu'
    )
    
    # 2. ÌÖåÏä§Ìä∏Ìï† Ïù¥ÎØ∏ÏßÄ Î™©Î°ù
    test_images = [
        ('test_unknown.jpg', 'ÏôÑÏ†Ñ Ï≤òÏùå Î≥¥Îäî Ïù¥ÎØ∏ÏßÄ'),
        ('test_image.jpg', 'Test Îç∞Ïù¥ÌÑ∞ÏÖã Ïù¥ÎØ∏ÏßÄ'),
        ('train_image.jpg', 'Train Îç∞Ïù¥ÌÑ∞ÏÖã Ïù¥ÎØ∏ÏßÄ'),
    ]
    
    # 3. Í∞Å Ïù¥ÎØ∏ÏßÄ ÌÖåÏä§Ìä∏
    for image_path, description in test_images:
        if os.path.exists(image_path):
            print(f"\n{'='*60}")
            print(f"ÌÖåÏä§Ìä∏: {description} ({image_path})")
            print('='*60)
            
            image = cv2.imread(image_path)
            
            # ÎîîÎ≤ÑÍ∑∏ Î™®ÎìúÎ°ú ÏòàÏ∏°
            result = recognizer.predict_single(image, debug=True)
            
            print(f"\n========== ÏòàÏ∏° Í≤∞Í≥º ==========")
            print(f"ÌÅ¥ÎûòÏä§: {result['class_name']}")
            print(f"Ïã†Î¢∞ÎèÑ: {result['confidence']:.3f}")
            print(f"Known Ïó¨Î∂Ä: {result['is_known']}")
            
            if not result['is_known']:
                print(f"Í±∞Î∂Ä Ïù¥Ïú†: {', '.join(result['rejection_reasons'])}")
            
            print(f"\nÏÑ∏Î∂Ä Ï†êÏàò:")
            for key, value in result['details'].items():
                print(f"  - {key}: {value:.4f}")
        else:
            print(f"\n‚ö†Ô∏è ÌååÏùº ÏóÜÏùå: {image_path}")