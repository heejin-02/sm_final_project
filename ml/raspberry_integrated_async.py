#!/usr/bin/env python3
"""
ë¼ì¦ˆë² ë¦¬íŒŒì´ í†µí•© í•´ì¶© íƒì§€ ì‹œìŠ¤í…œ - ì™„ì „ ë¹„ë™ê¸° ë²„ì „
ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ë¹„ë™ê¸° ì²˜ë¦¬
"""

import cv2
import numpy as np
import torch
import json
import time
import os
from datetime import datetime, timedelta
from collections import defaultdict
import asyncio
import aiohttp
import aiofiles
from pathlib import Path
import logging
from concurrent.futures import ThreadPoolExecutor
import threading
from queue import Queue

# ê¸°ì¡´ import
from raspberry_integrated import SimpleTracker

class AsyncMobileNetDetector:
    """ë¹„ë™ê¸° MobileNet íƒì§€ê¸°"""
    def __init__(self, model_path, confidence_threshold=0.6):
        self.device = torch.device('cpu')
        self.confidence_threshold = confidence_threshold
        self.model = self._load_model(model_path)
        self.model.eval()
        self.transform = self._get_transform()
        
        # í´ë˜ìŠ¤ ì´ë¦„
        self.class_names = [
            "ê½ƒë…¸ë‘ì´ì±„ë²Œë ˆ", "ë‹´ë°°ê°€ë£¨ì´", "ë¹„ë‹¨ë…¸ë¦°ì¬", "ì•Œë½ìˆ˜ì—¼ë…¸ë¦°ì¬",
            "ë¨¹ë…¸ë¦°ì¬", "ë¬´ìë²Œ", "ë°°ì¶”ì¢€ë‚˜ë°©", "ë²¼ë£©ìë²Œë ˆ",
            "ë³µìˆ­ì•„í˜¹ì§„ë”§ë¬¼", "í°28ì ë°•ì´ë¬´ë‹¹ë²Œë ˆ"
        ]
        
        # CPU ì§‘ì•½ì  ì‘ì—…ìš© ìŠ¤ë ˆë“œí’€
        self.executor = ThreadPoolExecutor(max_workers=2)
    
    def _load_model(self, model_path):
        """ëª¨ë¸ ë¡œë“œ"""
        from torchvision import models
        import torch.nn as nn
        
        model = models.mobilenet_v2(pretrained=False)
        in_features = model.classifier[1].in_features
        model.classifier = nn.Sequential(
            nn.Dropout(0.2),
            nn.Linear(in_features, 256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, 10)
        )
        
        checkpoint = torch.load(model_path, map_location=self.device)
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint)
        
        return model
    
    def _get_transform(self):
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        from torchvision import transforms
        return transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
    
    def _detect_sync(self, frame, roi=None):
        """ë™ê¸° íƒì§€ (ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰)"""
        detections = []
        h, w = frame.shape[:2]
        
        if roi:
            x1, y1, x2, y2 = roi
            roi_frame = frame[y1:y2, x1:x2]
        else:
            roi_frame = frame
            x1, y1 = 0, 0
        
        # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°
        window_size = 128
        stride = 64
        
        for y in range(0, roi_frame.shape[0] - window_size, stride):
            for x in range(0, roi_frame.shape[1] - window_size, stride):
                window = roi_frame[y:y+window_size, x:x+window_size]
                input_tensor = self.transform(window).unsqueeze(0)
                
                with torch.no_grad():
                    outputs = self.model(input_tensor)
                    probs = torch.softmax(outputs, dim=1)
                    conf, pred_class = probs.max(1)
                
                if conf > self.confidence_threshold:
                    detections.append({
                        'bbox': [x1+x, y1+y, x1+x+window_size, y1+y+window_size],
                        'confidence': float(conf),
                        'class_id': int(pred_class),
                        'class_name': self.class_names[pred_class]
                    })
        
        return detections
    
    async def detect_async(self, frame, roi=None):
        """ë¹„ë™ê¸° íƒì§€"""
        loop = asyncio.get_event_loop()
        # CPU ì§‘ì•½ì  ì‘ì—…ì„ ìŠ¤ë ˆë“œí’€ì—ì„œ ì‹¤í–‰
        detections = await loop.run_in_executor(
            self.executor,
            self._detect_sync,
            frame,
            roi
        )
        return detections

class AsyncVideoWriter:
    """ë¹„ë™ê¸° ë¹„ë””ì˜¤ ì €ì¥"""
    def __init__(self):
        self.write_queue = Queue()
        self.writer_thread = None
        self.writer = None
        
    async def start(self, filename, fps, size):
        """ë¹„ë™ê¸° ì“°ê¸° ì‹œì‘"""
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(None, self._start_sync, filename, fps, size)
    
    def _start_sync(self, filename, fps, size):
        """ë™ê¸° ì“°ê¸° ì‹œì‘"""
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        self.writer = cv2.VideoWriter(filename, fourcc, fps, size)
        
        # ì“°ê¸° ìŠ¤ë ˆë“œ ì‹œì‘
        self.writer_thread = threading.Thread(target=self._writer_worker)
        self.writer_thread.start()
    
    def _writer_worker(self):
        """ë°±ê·¸ë¼ìš´ë“œ ì“°ê¸° ì›Œì»¤"""
        while True:
            frame = self.write_queue.get()
            if frame is None:  # ì¢…ë£Œ ì‹ í˜¸
                break
            self.writer.write(frame)
    
    async def write_frame(self, frame):
        """í”„ë ˆì„ ì¶”ê°€ (ë…¼ë¸”ë¡œí‚¹)"""
        self.write_queue.put(frame)
    
    async def finish(self):
        """ì“°ê¸° ì™„ë£Œ"""
        self.write_queue.put(None)  # ì¢…ë£Œ ì‹ í˜¸
        if self.writer_thread:
            self.writer_thread.join()
        if self.writer:
            self.writer.release()

class AsyncSpringBootMonitor:
    """ì™„ì „ ë¹„ë™ê¸° Spring Boot ì—°ë™ ëª¨ë‹ˆí„°"""
    
    def __init__(self, camera_id=0, spring_url="http://192.168.219.49:8095", ml_url="http://192.168.219.49:8003"):
        self.camera_id = camera_id
        self.spring_url = spring_url
        self.ml_url = ml_url
        self.greenhouse_id = 75
        
        # ë¹„ë™ê¸° ì»´í¬ë„ŒíŠ¸
        self.detector = AsyncMobileNetDetector('best_mobilenet_insect.pt')
        self.tracker = SimpleTracker()
        
        # ì¹´ë©”ë¼
        self.cap = cv2.VideoCapture(camera_id)
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        self.cap.set(cv2.CAP_PROP_FPS, 10)
        
        # ìƒíƒœ
        self.insect_counts = defaultdict(int)
        self.last_count = 0
        self.recording = False
        self.record_frames = []
        self.metadata = []
        
        # ì•Œë¦¼ ì¿¨ë‹¤ìš´
        self.alert_cooldown = {}
        self.cooldown_minutes = 30
        
        # í”„ë ˆì„ ì½ê¸°ìš© ìŠ¤ë ˆë“œí’€
        self.frame_executor = ThreadPoolExecutor(max_workers=1)
        
        # HTTP ì„¸ì…˜ (ì¬ì‚¬ìš©)
        self.session = None
        
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
    
    async def read_frame_async(self):
        """ë¹„ë™ê¸° í”„ë ˆì„ ì½ê¸°"""
        loop = asyncio.get_event_loop()
        ret, frame = await loop.run_in_executor(
            self.frame_executor,
            self.cap.read
        )
        return ret, frame
    
    async def run(self):
        """ë©”ì¸ ì‹¤í–‰ ë£¨í”„"""
        # HTTP ì„¸ì…˜ ìƒì„±
        self.session = aiohttp.ClientSession()
        
        frame_count = 0
        
        try:
            while True:
                # ë¹„ë™ê¸° í”„ë ˆì„ ì½ê¸°
                ret, frame = await self.read_frame_async()
                if not ret:
                    await asyncio.sleep(0.01)
                    continue
                
                frame_count += 1
                
                # 3í”„ë ˆì„ë§ˆë‹¤ íƒì§€
                if frame_count % 3 == 0:
                    # ë¹„ë™ê¸° íƒì§€
                    detections = await self.detector.detect_async(frame)
                    
                    # ì¶”ì  ì—…ë°ì´íŠ¸ (ë¹ ë¥¸ ì—°ì‚°)
                    tracked = self.tracker.update(detections)
                    
                    # ë§ˆë¦¿ìˆ˜ ë³€í™” ê°ì§€
                    current_count = len(self.tracker.tracks)
                    if current_count > self.last_count:
                        self.logger.info(f"ğŸ› ìƒˆë¡œìš´ í•´ì¶© íƒì§€! (ì´ {current_count}ë§ˆë¦¬)")
                        
                        if not self.recording:
                            # ë¹„ë™ê¸° ë…¹í™” ì‹œì‘ (ë…¼ë¸”ë¡œí‚¹)
                            asyncio.create_task(self.start_recording(frame, tracked))
                    
                    self.last_count = current_count
                    
                    # ì‹œê°í™” (ì„ íƒì‚¬í•­)
                    # await self.visualize_async(frame, tracked)
                
                # í‚¤ ì…ë ¥ ì²´í¬ (ë…¼ë¸”ë¡œí‚¹)
                await asyncio.sleep(0.001)
                
        finally:
            await self.cleanup()
    
    async def start_recording(self, trigger_frame, initial_detections):
        """ë¹„ë™ê¸° 10ì´ˆ ë…¹í™”"""
        self.recording = True
        self.record_frames = []
        self.metadata = []
        
        timestamp = datetime.now()
        recording_start_time = time.time()
        
        # ë¹„ë™ê¸° ë¹„ë””ì˜¤ ì“°ê¸° ì¤€ë¹„
        video_writer = AsyncVideoWriter()
        temp_video = f"temp_{timestamp.strftime('%Y%m%d_%H%M%S')}.mp4"
        h, w = trigger_frame.shape[:2]
        await video_writer.start(temp_video, 10.0, (w, h))
        
        # 10ì´ˆê°„ ë…¹í™”
        while time.time() - recording_start_time < 10:
            ret, frame = await self.read_frame_async()
            if not ret:
                continue
            
            # ë¹„ë™ê¸° í”„ë ˆì„ ì“°ê¸°
            await video_writer.write_frame(frame)
            self.record_frames.append(frame)
            
            # ë¹„ë™ê¸° íƒì§€ (ë°±ê·¸ë¼ìš´ë“œ)
            if len(self.record_frames) % 5 == 0:  # 5í”„ë ˆì„ë§ˆë‹¤
                detections = await self.detector.detect_async(frame)
                tracked = self.tracker.update(detections)
                
                for detection in tracked:
                    bbox = detection['bbox']
                    x1, y1, x2, y2 = map(int, bbox)
                    crop = frame[y1:y2, x1:x2]
                    
                    self.metadata.append({
                        'frame_id': len(self.record_frames),
                        'timestamp': (timestamp + timedelta(seconds=len(self.record_frames)/10)).isoformat(),
                        'track_id': detection['track_id'],
                        'class_id': detection['class_id'],
                        'class_name': detection['class_name'],
                        'confidence': detection['confidence'],
                        'bbox': bbox,
                        'crop_image': crop
                    })
            
            await asyncio.sleep(0.05)  # ë‹¤ë¥¸ íƒœìŠ¤í¬ì— ì–‘ë³´
        
        # ë¹„ë””ì˜¤ ì“°ê¸° ì™„ë£Œ
        await video_writer.finish()
        
        # ë³‘ë ¬ ì²˜ë¦¬: ì—…ë¡œë“œì™€ ML ì²˜ë¦¬
        upload_task = asyncio.create_task(self.upload_to_spring_boot_async(temp_video))
        
        # ì—…ë¡œë“œ ì™„ë£Œ ëŒ€ê¸°
        video_path = await upload_task
        
        if video_path:
            # ML ì²˜ë¦¬ (ë¹„ë™ê¸°)
            await self.process_with_ml_server_async(video_path)
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        try:
            os.remove(temp_video)
        except:
            pass
        
        self.recording = False
    
    async def upload_to_spring_boot_async(self, video_file):
        """ì™„ì „ ë¹„ë™ê¸° Spring Boot ì—…ë¡œë“œ"""
        try:
            # aiofilesë¡œ ë¹„ë™ê¸° íŒŒì¼ ì½ê¸°
            async with aiofiles.open(video_file, 'rb') as f:
                video_data = await f.read()
            
            # FormData ìƒì„±
            data = aiohttp.FormData()
            data.add_field('video',
                          video_data,
                          filename='detection.mp4',
                          content_type='video/mp4')
            data.add_field('camera_id', f'cam_{self.camera_id:03d}')
            data.add_field('gh_idx', str(self.greenhouse_id))
            data.add_field('detection_count', str(len(set(d['track_id'] for d in self.metadata))))
            data.add_field('recording_start_time', str(time.time()))
            data.add_field('frame_count', str(len(self.record_frames)))
            
            # ë¹„ë™ê¸° HTTP POST
            async with self.session.post(
                f"{self.spring_url}/api/video/upload",
                data=data,
                timeout=aiohttp.ClientTimeout(total=30)
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    video_path = result.get('video_path')
                    img_idx = result.get('img_idx')
                    
                    self.logger.info(f"âœ… Spring Boot ì—…ë¡œë“œ ì„±ê³µ: {video_path}")
                    
                    for item in self.metadata:
                        item['img_idx'] = img_idx
                    
                    return video_path
                else:
                    self.logger.error(f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {response.status}")
                    return None
                    
        except Exception as e:
            self.logger.error(f"âŒ ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None
    
    async def process_with_ml_server_async(self, video_path):
        """ë¹„ë™ê¸° ML ì„œë²„ ì²˜ë¦¬"""
        try:
            metadata_payload = {
                'greenhouse_id': self.greenhouse_id,
                'video_path': video_path,
                'detections': []
            }
            
            # í¬ë¡­ ì´ë¯¸ì§€ ì²˜ë¦¬
            for detection in self.metadata[:100]:  # ìµœëŒ€ 100ê°œ
                crop_image = detection.pop('crop_image')
                _, buffer = cv2.imencode('.jpg', crop_image)
                image_base64 = buffer.tobytes().hex()
                detection['crop_base64'] = image_base64
                metadata_payload['detections'].append(detection)
            
            # ë¹„ë™ê¸° POST
            async with self.session.post(
                f"{self.ml_url}/api/process-detections",
                json=metadata_payload,
                timeout=aiohttp.ClientTimeout(total=60)
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    
                    # ì•Œë¦¼ ì²˜ë¦¬ (ë¹„ë™ê¸°)
                    await self.handle_alerts_async(result)
                    
                    self.logger.info(f"âœ… ML ì²˜ë¦¬ ì™„ë£Œ")
                else:
                    self.logger.error(f"âŒ ML ì²˜ë¦¬ ì‹¤íŒ¨: {response.status}")
                    
        except Exception as e:
            self.logger.error(f"âŒ ML ì˜¤ë¥˜: {e}")
    
    async def handle_alerts_async(self, ml_result):
        """ë¹„ë™ê¸° ì•Œë¦¼ ì²˜ë¦¬"""
        alerts = ml_result.get('alerts', [])
        
        # ë³‘ë ¬ ì•Œë¦¼ ì²˜ë¦¬
        alert_tasks = []
        for alert in alerts:
            if self.check_cooldown(alert['insect_type']):
                alert_tasks.append(
                    asyncio.create_task(self.send_alert_async(alert))
                )
        
        # ëª¨ë“  ì•Œë¦¼ ì™„ë£Œ ëŒ€ê¸°
        if alert_tasks:
            await asyncio.gather(*alert_tasks)
    
    async def send_alert_async(self, alert):
        """ë¹„ë™ê¸° ì•Œë¦¼ ë°œì†¡"""
        try:
            # ì „í™”ë²ˆí˜¸ ì¡°íšŒ
            async with self.session.get(
                f"{self.spring_url}/ml/user-phone-by-ghidx",
                params={'gh_idx': self.greenhouse_id}
            ) as resp:
                if resp.status == 200:
                    phone_data = await resp.json()
                    
                    # SignalWire ë°œì‹ 
                    call_data = {
                        'to_number': phone_data.get('userPhone'),
                        'message': f"{alert['insect_type']} ë°œê²¬. ì‹ ë¢°ë„ {alert['confidence']:.0%}"
                    }
                    
                    async with self.session.post(
                        f"{self.ml_url}/api/make-call",
                        json=call_data
                    ) as call_resp:
                        if call_resp.status == 200:
                            self.logger.info(f"ğŸ“ ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ")
                            
        except Exception as e:
            self.logger.error(f"âŒ ì•Œë¦¼ ì˜¤ë¥˜: {e}")
    
    def check_cooldown(self, insect_type):
        """ì¿¨ë‹¤ìš´ ì²´í¬"""
        key = f"{self.greenhouse_id}_{insect_type}"
        now = datetime.now()
        
        if key in self.alert_cooldown:
            last_alert = self.alert_cooldown[key]
            if (now - last_alert).seconds < self.cooldown_minutes * 60:
                return False
        
        self.alert_cooldown[key] = now
        return True
    
    async def cleanup(self):
        """ì •ë¦¬"""
        if self.session:
            await self.session.close()
        
        self.cap.release()
        cv2.destroyAllWindows()
        
        # ìŠ¤ë ˆë“œí’€ ì¢…ë£Œ
        self.detector.executor.shutdown(wait=False)
        self.frame_executor.shutdown(wait=False)
        
        self.logger.info("ğŸ”š ì¢…ë£Œ")

if __name__ == "__main__":
    monitor = AsyncSpringBootMonitor()
    asyncio.run(monitor.run())

# ì¶”ê°€ í•„ìš” íŒ¨í‚¤ì§€:
# pip install aiofiles aiohttp